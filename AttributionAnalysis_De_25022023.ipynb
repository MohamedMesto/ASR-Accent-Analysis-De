{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roshdl_R_SVy"
      },
      "source": [
        "# <font color=\"00ff00\">  **Statistical Analysis for Accented Speech recognition**</font>\n",
        "<font color=white> **evaluates the performance of an ASR model regarding accented speech**</font> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpDghOOKRF9n"
      },
      "source": [
        "# <font color=\"00ff00\">  **Statistical Analysis for Accented Speech recognition**</font>\n",
        "<font color=white> **evaluates the performance of an ASR model regarding accented speech**</font> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTQqnW3mRF9p"
      },
      "source": [
        "## <font color=\"00ff00\">  **Analyze results from Carlos’ model**</font>\n",
        "<font color=white> **Using Gradient-based techniques:**</font> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaIxeKyVRF9p"
      },
      "source": [
        "## <font color=\"00ff00\">  **3- Gradient-based Analysis**</font>\n",
        "<font color=white> **simple gradient-based explanation method considers the gradient of the output $f_j$ from a neural network (where j denotes a target class) with respect to an input $x_i$ (where i refers to the ith input time-step used to index the input sequence $x$):**</font> \n",
        "\n",
        "<font color=white>\n",
        "$grad(j,i,x)={\\displaystyle \\frac{\\partial f_j}{\\partial x_i}}$</font>\n",
        "\n",
        "\n",
        " <font color=\"00ff00\">  **3.1 Attribution Analysis**</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HwkaB-qW3AUn"
      },
      "outputs": [],
      "source": [
        "# ! pip install Nemo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cydRZFRhurMx"
      },
      "outputs": [],
      "source": [
        "# import nemo.collections.asr as nemo_asr\n",
        "# asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name=\"stt_de_conformer_transducer_large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYkx10eEurz5"
      },
      "source": [
        "*********************************************************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b69My7nmRF9q",
        "outputId": "a5472240-6eba-4e4f-8e1c-f7f3c121cb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hyphenate\n",
            "  Downloading Hyphenate-1.1.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: hyphenate\n",
            "Successfully installed hyphenate-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.20.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.20.9\n",
            "  Downloading Levenshtein-0.20.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.20.9 python-Levenshtein-0.20.9 rapidfuzz-2.13.7\n"
          ]
        }
      ],
      "source": [
        "!pip install hyphenate\n",
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ptgMGEOuRF9q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from scipy.io import wavfile\n",
        "from itertools import chain \n",
        "import string\n",
        "import Levenshtein as Lev\n",
        "from itertools import groupby\n",
        "import scipy.stats as st\n",
        "from scipy import signal\n",
        "import nltk\n",
        "from scipy.stats import wasserstein_distance as wd\n",
        "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
        "from pyemd import emd\n",
        "from hyphenate import hyphenate_word\n",
        "from itertools import islice \n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM6vhd0CRF9r"
      },
      "source": [
        "###<font color=\"00ff00\">  **Set up dataframe for transcripts and files:**</font>\n",
        "<font color=white> **Set up dataframe for transcripts and files- Test_accent.txt file case:**</font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RM-H-0eTRF9r"
      },
      "outputs": [],
      "source": [
        "# Import the dataset file by method1 \n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "\n",
        "\n",
        "! cp /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/cv-corpus04072022/de/validated.tsv /content/validated.tsv\n",
        "\n",
        "# copy the expermintations files to deal with them\n",
        "\n",
        "! cp /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/*.* /content/\n",
        "\n",
        "# copy the expermintations files from Mozilla Commen Voice v 10 to deal with them"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title read in all three CSV files at once and store them in separate dataframes\n",
        "\n",
        "\n",
        "# # my_data/all_overlap.txt ==>> test_at.txt\n",
        "# # transcript ==>> text\n",
        "# # file==>> audio_filepath\n",
        "# # all_overlap ==>> dataset_trans_test_all_output.csv\n",
        "# ###############################################\n",
        "\n",
        "# df_at, df_gb, df_it, df_de_al, df_fr, df_de_ni, df_ch, df_de, df_us, df_ca, df_ru = pd.read_csv(['test_at.txt', 'test_gb.txt', 'test_it.txt', 'test_de_al.txt', 'test_fr.txt',\n",
        "#                                'test_de_ni.txt', 'test_ch.txt', 'test_de.txt', 'test_us.txt', 'test_ca.txt', 'test_ru.txt'] )\n",
        "\n",
        "df_at= pd.read_csv('test_at.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_gb= pd.read_csv('test_gb.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_it= pd.read_csv( 'test_it.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_de_al= pd.read_csv('test_de_al.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_fr= pd.read_csv('test_fr.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_de_ni= pd.read_csv( 'test_de_ni.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_ch= pd.read_csv('test_ch.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_de= pd.read_csv('test_de.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_us= pd.read_csv( 'test_us.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_ca= pd.read_csv('test_ca.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        "df_ru= pd.read_csv('test_ru.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
        " \n",
        "# combine the dataframes into a single one \n",
        "combined_df = pd.concat([df_at, df_gb, df_it, df_de_al, df_fr, df_de_ni, df_ch, df_de, df_us, df_ca, df_ru], ignore_index=True)\n",
        "\n",
        "dataset_trans=combined_df\n",
        "\n",
        "dataset_trans['audio_filepath'] = dataset_trans['audio_filepath'].map(lambda x: x.split('.',6)[2])\n",
        "dataset_trans['audio_filepath'] = dataset_trans['audio_filepath'].map(lambda x: x.split('/',6)[3])\n",
        "dataset_trans['transcript'] = dataset_trans['transcript'].map(lambda x: x.split('\": \"',2)[1])\n",
        "dataset_trans['transcript'] = dataset_trans['transcript'].map(lambda x: x.split('\"',2)[0])\n",
        "dataset_trans['duration'] = dataset_trans['duration'].map(lambda x: x.split('\": ',2)[1])\n",
        "dataset_trans['duration'] = dataset_trans['duration'].map(lambda x: x.split('}',2)[0])\n",
        "    \n",
        "\n",
        "print(type(dataset_trans),'\\n',dataset_trans.head(10))\n",
        "\n",
        "print(len(dataset_trans))\n",
        "# the complete final dataframe of all Accents txt files\n",
        "dataset_trans.to_csv( 'dataset_trans_test_all_output.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WycLrfavlSVR",
        "outputId": "c54c3d81-a0e4-4c73-9a7d-2bef9aa64aad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> \n",
            "              audio_filepath  \\\n",
            "0  common_voice_de_31449916   \n",
            "1  common_voice_de_19730674   \n",
            "2  common_voice_de_19703888   \n",
            "3  common_voice_de_18507972   \n",
            "4  common_voice_de_24131267   \n",
            "5  common_voice_de_21905399   \n",
            "6  common_voice_de_20143462   \n",
            "7  common_voice_de_21889444   \n",
            "8  common_voice_de_18192538   \n",
            "9  common_voice_de_19615389   \n",
            "\n",
            "                                          transcript duration  \n",
            "0  er ist nach eustache de saint pierre der bekan...      4.9  \n",
            "1  eine erste kleinformatige vorstudie in bleisti...     10.1  \n",
            "2  er blieb ohne erfolg und lag in ständigem stre...      9.0  \n",
            "3      mein garten ist teil eines kleingartenvereins      3.7  \n",
            "4      was habe ich damals für einen unsinn geträumt      3.6  \n",
            "5  der erste punkt bezieht sich auf die angst vor...      5.2  \n",
            "6  anschließend war er bei der regierung in düsse...      4.1  \n",
            "7  jede quersubventionierung soll in zukunft unzu...     10.4  \n",
            "8  silke und marco verkrümelten sich unauffällig ...      4.7  \n",
            "9  im frieden wurde die volksmarine aus dem komma...      9.0  \n",
            "49230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf26Pu1rRF9t",
        "outputId": "5759971c-2435-4e0e-91ba-66cb502ddaed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        er ist nach eustache de saint pierre der bekan...\n",
              "1        eine erste kleinformatige vorstudie in bleisti...\n",
              "2        er blieb ohne erfolg und lag in ständigem stre...\n",
              "3            mein garten ist teil eines kleingartenvereins\n",
              "4            was habe ich damals für einen unsinn geträumt\n",
              "                               ...                        \n",
              "49225                           sie kramte in ihrer tasche\n",
              "49226              libreville ist die hauptstadt von gabun\n",
              "49227    das ramponierte image haben sie sich selbst zu...\n",
              "49228               er macht einen unterforderten eindruck\n",
              "49229    mit der kippe sind sie für ihr kind gefährlich...\n",
              "Name: transcript, Length: 49230, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset_trans['transcript']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "544K28TzRF9t",
        "outputId": "a9d92fbb-51c1-46d7-c4ec-651afc39fe14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39087"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "transcripts = list(set(dataset_trans['transcript'].tolist()))\n",
        "len(transcripts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vdGmOHcRF9t",
        "outputId": "ab858e3f-34b1-4079-a424-574cfca37210"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "type(transcripts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Dk3HX6crRF9u"
      },
      "outputs": [],
      "source": [
        "trans_dict = {x:[] for x in transcripts}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCTPjzySRF9u",
        "outputId": "66d240e9-51f8-4cd9-fae4-2ef6eb395eb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39087"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(trans_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u031LcfARF9u"
      },
      "outputs": [],
      "source": [
        "# Assign the row['transcript'] value to the \n",
        "for index, row in dataset_trans.iterrows():\n",
        "    trans_dict[row['transcript']].append(row['audio_filepath'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMKZdPcxRF9u",
        "outputId": "31993542-100e-41e8-a8fd-ac31a8b0ac5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['common_voice_de_20411523']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trans_dict['als zweiter teil einer geplanten tetralogie wurde es ins deutsche übersetzt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzjvieZjRF9u",
        "outputId": "822cbee9-50b1-40ca-becc-f19845a0888a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('die regierungen haben sich europa in den weg gestellt',\n",
              "  ['common_voice_de_21955762']),\n",
              " ('liv liva olivia', ['common_voice_de_28758456']),\n",
              " ('schnick schnack schnuck', ['common_voice_de_18895238']),\n",
              " ('er lebt als freier schriftsteller in der niedersächsischen stadt otterndorf',\n",
              "  ['common_voice_de_19859248']),\n",
              " ('das ehepaar musste sich davon gewöhnlich durch die zahlung eines lösegelds befreien',\n",
              "  ['common_voice_de_20411836'])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "######################## show the first 5 rows of the dictionary trans_dict ##################################\n",
        "from itertools import islice\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "n_items = take(5, trans_dict.items())\n",
        "n_items \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_0TjQHmRF9u",
        "outputId": "d8104b36-9446-4aab-bf4e-60308d42b688"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['common_voice_de_17686048', 'common_voice_de_17650552']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "##### find the Audio file name\n",
        "trans_dict['findest du dich allein in braunschweig zurecht']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### find the Audio file name\n",
        "trans_dict['schreib ihr halt ein paar liebe worte rein']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UswOlVb1HV5N",
        "outputId": "20aa12be-aa10-4072-afd4-770567ed52f7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['common_voice_de_18946081', 'common_voice_de_18568843']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoCIoeeNRF9v"
      },
      "source": [
        "###<font color=\"00ff00\">  **Set up dataframe for transcripts and files:**</font>\n",
        "<font color=white> **Set up dataframe for transcripts and files- Results.json file case:**</font> \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtkFSfiMRF9v",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title store the contents of Accented files in an extra text files respekt Ä Ö Ü ß\n",
        "################################## store the contents of Accented files in an extra text files respekt Ä Ö Ü ß ##################################### \n",
        "####################################################################################################################################################\n",
        "import json\n",
        "if __name__ == \"__main__\":\n",
        "  results = json.load(open('results.json'),encoding=\"utf-8\")\n",
        "  # Required_text=input(\"inser thte sentence: \")\n",
        "  for test_file in results:\n",
        "    list_values = [v[\"reference\"] for v in results[test_file].values()]\n",
        "    # string(ref_lens)\n",
        "    # print(f'{test_file} \\n',ref_lens)\n",
        "    str_values = ', '.join(str(x) for x in list_values)\n",
        "    \n",
        "    # print(df_trans.head(10))\n",
        "\n",
        "    # len(df_trans)\n",
        "\n",
        "    import os\n",
        "    # remove the script if exists \n",
        "    # os.remove(\"dataset_accent.py\")\n",
        "    # open script to write in the calculation of Mean of all accent\n",
        "    dataset_accent_write_file = open(f'dataset_{test_file}.py','w')\n",
        "    dataset_accent_write_file.write(str_values)\n",
        "    dataset_accent_write_file.close()\n",
        "    ! cp /content/*.txt.py /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/test_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjz8UWrlRF9x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Creat Dictionary \"trans_dict_results\" of all Accent Audio files number and their Values\n",
        "\n",
        "########################################################################################################################################################\n",
        "############################# Creat Dictionary \"trans_dict_results\" of all Accent Audio files number and their Values###################################\n",
        "########################################################################################################################################################\n",
        "\n",
        "\n",
        "trans_dict_results = {'Keys_MMM_2050': '1000'}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  Dict_results = json.load(open('results.json'))\n",
        "  for test_file in Dict_results:\n",
        "    list_test_accent_txt_values = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
        "    # print('*********\\n',list_test_accent_txt_values)\n",
        "    # list_test_accent_txt_keys=[k.split('.',6)[2] for k in Dict_results[test_file].keys()]\n",
        "    list_test_accent_txt_keys=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
        "\n",
        "    trans_dict_test_file_result = dict(zip(list_test_accent_txt_keys, list_test_accent_txt_values))\n",
        "    trans_dict_results.update(trans_dict_test_file_result)\n",
        "    \n",
        "######################################## write the dictionary \"trans_dict\" to a json file ###############################\n",
        "with open(\"trans_dict_results.json\",\"w\", encoding='utf-8') as jsonfile:  \n",
        "  json.dump(trans_dict_results,jsonfile,ensure_ascii=False)\n",
        "! cp /content/trans_dict_results.json /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/test_data/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJjrdk_pRF9x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "### Show the first 10 elements of the dict\n",
        "n_items = take(5, trans_dict_results.items())\n",
        "n_items "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znI-C6vVRF9x"
      },
      "source": [
        "### <font color=white> **Display the Audio files number(Dict Key) of a given Utterance (Dict Value) and vice versa:**</font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UswnSTiGqw7W"
      },
      "outputs": [],
      "source": [
        "# # find if there are repeatation of a utterance in all German Accents\n",
        "# dataset_test_ca=pd.read_csv(\"dataset_test_ca.txt.py\", encoding=\"Utf-8\")\n",
        "# for i in dataset_test_ca:\n",
        "#   keys = [k for k, v in trans_dict_results.items() if v == i]\n",
        "#   if keys != []:\n",
        "#     print(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "t5RMVW4om_0_"
      },
      "outputs": [],
      "source": [
        "# # find the repeatation of a sentence in all German Accents\n",
        "# dataset_test_ch=pd.read_csv(\"dataset_test_ch.txt.py\",sep=',' ,encoding=\"Utf-8\")\n",
        "# for i in dataset_test_ch:\n",
        "#   keys = [k for k, v in trans_dict_results.items() if v == i]\n",
        "#   if keys != []:\n",
        "#     print(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "E5Phi8BBgHVS"
      },
      "outputs": [],
      "source": [
        "# # find all the Audio files for a sentence\n",
        "# dataset_test_ch=pd.read_csv(\"dataset_test_ch.txt.py\", encoding=\"Utf-8\")\n",
        "# list_test_ch=[]\n",
        "# for i in dataset_test_ch:\n",
        "#   print((i))\n",
        "#   # list_test_ca.append"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqDUrkNPRF9x"
      },
      "source": [
        "### <font color=\"00ff00\">  **Display the Audio files number(Dict Key) of a given Word (Dict Value):**</font>\n",
        "<font color=white> **We selected the fllowing 8 Words rather than 8 Utterances, due no enough Utterances in all Accents:**</font> \n",
        "\n",
        "<font color=white>\n",
        "\n",
        "1. höchsten \n",
        "2. völlig \n",
        "3. südlichen\n",
        "4. gefährlich\n",
        "5. hauptsächlich\n",
        "6. später\n",
        "7. geschäftsordnung\n",
        "8. präsidentschaft \n",
        "</font> \n",
        "\n",
        "\n",
        "### <font color=white> ****</font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6zhgwsDRF9y"
      },
      "outputs": [],
      "source": [
        "# ###############################################################\n",
        "# #### show the Audio files for a given Word ####################\n",
        "# for key, value in trans_dict_results.items():\n",
        "#       if \"höchsten\" in value:\n",
        "#         print(key)\n",
        "#         Audio_file_key=key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpTxYVutT7KS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ###**According to a given utterance, this code shows and writes in which Audio files and which Accent this given utterance is located:**\n",
        "\n",
        "###########################################################################################################################################################\n",
        "########### creat a Dataframe called \"dataset_audiofilename_transcript_accent\" contains all audiofilename and thier 'transcript' and 'test_file' /Accent####\n",
        "###########################################################################################################################################################\n",
        "list_dataset_test_=['test_at.txt','test_gb.txt','test_it.txt','test_de_al.txt','test_fr.txt','test_de_ni.txt','test_ch.txt',\n",
        "               'test_de.txt','test_us.txt','test_ca.txt','test_ru.txt']\n",
        "list_dataset_test_accent=['Österreichisches Deutsch','Britisches Deutsch','Italienisch Deutsch','Alemannische Färbung,Schweizer Standart Deutsch',\n",
        "'Französisch Deutsch','Niederländisch Deutsch','Schweizerdeutsch','Deutschland Deutsch','Amerikanisches Deutsch','Kanadisches Deutsch','Russisch Deutsch']\n",
        "\n",
        "data_dict_accent_duration  = dict(zip( list_dataset_test_, list_dataset_test_accent))  \n",
        "\n",
        "\n",
        "### here is the required_utterance\n",
        "required_utterance=\"findest du dich allein in braunschweig zurecht\"\n",
        "newfile=0\n",
        "# dict_audiofilename_transcript_accent=[]\n",
        "# To find out the Audio file's Accent\n",
        "list_test_accent_txt_values=[]\n",
        "list_test_accent_txt_keys=[]\n",
        "list_test_file=[]\n",
        "list_accent_long=[]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  Dict_results = json.load(open('results.json'))\n",
        "  for test_file in Dict_results:\n",
        "    # print(test_file)\n",
        "    list_test_accent_txt_values_temp = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
        "    list_test_accent_txt_keys_temp=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
        "    list_test_file_temp=[test_file for v in Dict_results[test_file].values()]\n",
        "\n",
        "# creat a Dataframe called  dataset_audiofilename_transcript_accent contains all audiofilename and thier 'transcript' and 'test_file' /Accent\n",
        "    list_test_accent_txt_values.extend(list_test_accent_txt_values_temp)\n",
        "    list_test_accent_txt_keys.extend(list_test_accent_txt_keys_temp)\n",
        "    list_test_file.extend(list_test_file_temp)\n",
        "    keys=['audiofilename','transcript','test_file']\n",
        "    trans_dict_test_file_result = dict(zip(keys,[list_test_accent_txt_keys, list_test_accent_txt_values,list_test_file]))\n",
        "    \n",
        "dataset_audiofilename_transcript_accent = pd.DataFrame(trans_dict_test_file_result)\n",
        "\n",
        "#############################################################################################\n",
        "##### Show and write which Audio files and which Accent the given word is located ###########\n",
        "\n",
        "for key, value in dataset_audiofilename_transcript_accent['transcript'].items():\n",
        "  if required_utterance in value:\n",
        "\n",
        "# to show the full name accent of the founded result \n",
        "    for keys_accent_long_i, values_accent_long_i in data_dict_accent_duration.items():\n",
        "      if dataset_audiofilename_transcript_accent.test_file[key]==keys_accent_long_i:\n",
        "        print()\n",
        "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        # f'*** Accent ={dataset_audiofilename_transcript_accent.test_file[key]}')\n",
        "        print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "              f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}')\n",
        "\n",
        "\n",
        "        # # Alternative way (for speed performance) to export the Audio files numbers and thiers Acccent to an external file\n",
        "        # # os.mkdir('/content/audiofilenames_transcript')\n",
        "\n",
        "        # if newfile==0:\n",
        "        #   dataset_accent_write_file = open(f'audiofilenames_transcript_accent_of_an_utterance.txt','w')\n",
        "        #   newfile=1\n",
        "        # else:\n",
        "        #   dataset_accent_write_file = open(f'audiofilenames_transcript_accent_of_an_utterance.txt','a')\n",
        "        #   dataset_accent_write_file.write(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        #       f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}\\n')\n",
        "        #   dataset_accent_write_file.close()\n",
        "        #   # ! cp /content/audiofilenames_transcript/*.txt /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/test_data/audiofilenames_transcript/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnGo6Bk6Bk6I",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ###**According to a given word, this code shows and writes in which Audio files and which Accent this given word is located:**\n",
        "\n",
        "###########################################################################################################################################################\n",
        "########### creat a Dataframe called \"dataset_audiofilename_transcript_accent\" contains all audiofilename and thier 'transcript' and 'test_file' /Accent####\n",
        "###########################################################################################################################################################\n",
        "list_dataset_test_=['test_at.txt','test_gb.txt','test_it.txt','test_de_al.txt','test_fr.txt','test_de_ni.txt','test_ch.txt',\n",
        "               'test_de.txt','test_us.txt','test_ca.txt','test_ru.txt']\n",
        "list_dataset_test_accent=['Österreichisches Deutsch','Britisches Deutsch','Italienisch Deutsch','Alemannische Färbung,Schweizer Standart Deutsch',\n",
        "'Französisch Deutsch','Niederländisch Deutsch','Schweizerdeutsch','Deutschland Deutsch','Amerikanisches Deutsch','Kanadisches Deutsch','Russisch Deutsch']\n",
        "\n",
        "data_dict_accent_duration  = dict(zip( list_dataset_test_, list_dataset_test_accent))  \n",
        "\n",
        "\n",
        "### here is the required_word\n",
        "required_word=\"höchsten\"\n",
        "newfile=0\n",
        "# dict_audiofilename_transcript_accent=[]\n",
        "# To find out the Audio file's Accent\n",
        "list_test_accent_txt_values=[]\n",
        "list_test_accent_txt_keys=[]\n",
        "list_test_file=[]\n",
        "list_accent_long=[]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  Dict_results = json.load(open('results.json'))\n",
        "  for test_file in Dict_results:\n",
        "    # print(test_file)\n",
        "    list_test_accent_txt_values_temp = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
        "    list_test_accent_txt_keys_temp=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
        "    list_test_file_temp=[test_file for v in Dict_results[test_file].values()]\n",
        "\n",
        "# creat a Dataframe called  dataset_audiofilename_transcript_accent contains all audiofilename and thier 'transcript' and 'test_file' /Accent\n",
        "    list_test_accent_txt_values.extend(list_test_accent_txt_values_temp)\n",
        "    list_test_accent_txt_keys.extend(list_test_accent_txt_keys_temp)\n",
        "    list_test_file.extend(list_test_file_temp)\n",
        "    keys=['audiofilename','transcript','test_file']\n",
        "    trans_dict_test_file_result = dict(zip(keys,[list_test_accent_txt_keys, list_test_accent_txt_values,list_test_file]))\n",
        "    \n",
        "dataset_audiofilename_transcript_accent = pd.DataFrame(trans_dict_test_file_result)\n",
        "\n",
        "#############################################################################################\n",
        "##### Show and write which Audio files and which Accent the given word is located ###########\n",
        "\n",
        "for key, value in dataset_audiofilename_transcript_accent['transcript'].items():\n",
        "  if required_word in value:\n",
        "\n",
        "# to show the full name accent of the founded result \n",
        "    for keys_accent_long_i, values_accent_long_i in data_dict_accent_duration.items():\n",
        "      if dataset_audiofilename_transcript_accent.test_file[key]==keys_accent_long_i:\n",
        "        print()\n",
        "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        # f'*** Accent ={dataset_audiofilename_transcript_accent.test_file[key]}')\n",
        "        print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "              f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}')\n",
        " \n",
        "\n",
        "          ## Alternative way (for speed performance) to export the Audio files numbers and thiers Acccent to an external file\n",
        "        if newfile==0:\n",
        "          dataset_accent_write_file = open(f'Audiofilesnumber_Accent.txt','w')\n",
        "          newfile=1\n",
        "        else:\n",
        "          dataset_accent_write_file = open(f'Audiofilesnumber_Accent_{required_word}.txt','a')\n",
        "          # dataset_accent_write_file.write(f'{key}the Audio file\\'s Accent file is {test_file}\\n')\n",
        "          dataset_accent_write_file.write(f' {dataset_audiofilename_transcript_accent.audiofilename[key]} ***{dataset_audiofilename_transcript_accent.transcript[key]} *** Accent is {data_dict_accent_duration[keys_accent_long_i]}')\n",
        "\n",
        "\n",
        "          dataset_accent_write_file.close()\n",
        "          ! cp /content/Audiofilesnumber_Accent*.txt /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/test_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nLsbbysR-KmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "cebb7d2a-cd20-4075-97af-cd14163ed128"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-1e93bf787873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrans_dict_test_file_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trans_dict_test_file_result' is not defined"
          ]
        }
      ],
      "source": [
        "for key, value in trans_dict_test_file_result.items():\n",
        "    print(key, value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#@title ###**According to a given word, this code shows and writes in which Audio files and which Accent this given word is located:**\n",
        "\n",
        "###########################################################################################################################################################\n",
        "########### creat a Dataframe called \"dataset_audiofilename_transcript_accent\" contains all audiofilename and thier 'transcript' and 'test_file' /Accent####\n",
        "###########################################################################################################################################################\n",
        "list_dataset_test_=['test_at.txt','test_gb.txt','test_it.txt','test_de_al.txt','test_fr.txt','test_de_ni.txt','test_ch.txt',\n",
        "               'test_de.txt','test_us.txt','test_ca.txt','test_ru.txt']\n",
        "list_dataset_test_accent=['Österreichisches Deutsch','Britisches Deutsch','Italienisch Deutsch','Alemannische Färbung,Schweizer Standart Deutsch',\n",
        "'Französisch Deutsch','Niederländisch Deutsch','Schweizerdeutsch','Deutschland Deutsch','Amerikanisches Deutsch','Kanadisches Deutsch','Russisch Deutsch']\n",
        "\n",
        "data_dict_accent_duration  = dict(zip( list_dataset_test_, list_dataset_test_accent))  \n",
        "\n",
        "# create an empty set to store the words that meet all 11 accents\n",
        "words = set()\n",
        "accent_long_set=set()\n",
        "accent_long_list=[]\n",
        " \n",
        "\n",
        "### here is the required_word\n",
        "required_word=\"Start\"\n",
        "# required_word=input('Insert a word to test it please? ')\n",
        "newfile=0\n",
        "\n",
        "# dict_audiofilename_transcript_accent=[]\n",
        "# To find out the Audio file's Accent\n",
        "list_test_accent_txt_values=[]\n",
        "list_test_accent_txt_keys=[]\n",
        "list_test_file=[]\n",
        "list_accent_long=[]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  Dict_results = json.load(open('results.json'))\n",
        "  for test_file in Dict_results:\n",
        "    # print(test_file)\n",
        "    list_test_accent_txt_values_temp = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
        "    list_test_accent_txt_keys_temp=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
        "    list_test_file_temp=[test_file for v in Dict_results[test_file].values()]\n",
        "\n",
        "# creat a Dataframe called  dataset_audiofilename_transcript_accent contains all audiofilename and thier 'transcript' and 'test_file' /Accent\n",
        "    list_test_accent_txt_values.extend(list_test_accent_txt_values_temp)\n",
        "    list_test_accent_txt_keys.extend(list_test_accent_txt_keys_temp)\n",
        "    list_test_file.extend(list_test_file_temp)\n",
        "    keys=['audiofilename','transcript','test_file']\n",
        "    trans_dict_test_file_result = dict(zip(keys,[list_test_accent_txt_keys, list_test_accent_txt_values,list_test_file]))\n",
        "    \n",
        "dataset_audiofilename_transcript_accent = pd.DataFrame(trans_dict_test_file_result)\n",
        " \n",
        "\n",
        "for key, row in dataset_audiofilename_transcript_accent.iterrows():\n",
        "  if required_word in row['transcript']:\n",
        "\n",
        "# to show the full name accent of the founded result \n",
        "    for keys_accent_long_i, values_accent_long_i in data_dict_accent_duration.items():\n",
        "      if dataset_audiofilename_transcript_accent.test_file[key]==keys_accent_long_i:\n",
        "        # print()\n",
        "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        # f'*** Accent ={dataset_audiofilename_transcript_accent.test_file[key]}')\n",
        "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        #       f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}')\n",
        "        accent_long_list.append(data_dict_accent_duration[keys_accent_long_i])\n",
        "        accent_long_str = ', '.join(accent_long_list)\n",
        "        accent_long_set=set(accent_long_str.split(', '))\n",
        "        # print(accent_long_str)\n",
        "\n",
        "        # get the accents for the current row\n",
        "        # accents = set(row['test_file'].split())\n",
        "        # accents = set(accent_long_set.split())\n",
        "        # print(len(accents))\n",
        "        # print('*'*60)\n",
        "        # check if the set of accents contains all 11 accents\n",
        "\n",
        "if len(accent_long_set) == 11:\n",
        "  print('*'*60)\n",
        "  print(f'Perfect, the Word {required_word} are found in all German accents')\n",
        "  print('*'*60)\n",
        "else:\n",
        "  print(f'unfortunately, the Word \"{required_word}\" are ***NOT*** found in all German accents')\n",
        "        # add the word to the set of words that meet all 11 accents\n",
        "#             words.add(row['transcript'])\n",
        "\n",
        "# # # print the words that meet all 11 accents\n",
        "# print('*'*60)\n",
        "# print(words)\n"
      ],
      "metadata": {
        "id": "EAB_n7YFBrAW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_audiofilename_transcript_accent"
      ],
      "metadata": {
        "id": "8_xKKOkkpDKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###<font color=\"00ff00\">  **To count the number of occurrences of each word over the sentences located in the transcripts column of a data frame:**</font>\n",
        "<font color=white> **the following steps are achieve that**</font> "
      ],
      "metadata": {
        "id": "mbDXpv9E04en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# First, import the required libraries. You will need the pandas library to work with data frames and the nltk library to tokenize the sentences and words in the transcripts column.\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "#@title ###**To count the number of occurrences of each word over the sentences located in the transcripts column of a data frame:**\n",
        "\n",
        "###########################################################################################################################################################\n",
        "########### creat a Dataframe called \"dataset_audiofilename_transcript_accent\" contains all audiofilename and thier 'transcript' and 'test_file' /Accent####\n",
        "###########################################################################################################################################################\n",
        "list_dataset_test_=['test_at.txt','test_gb.txt','test_it.txt','test_de_al.txt','test_fr.txt','test_de_ni.txt','test_ch.txt',\n",
        "               'test_de.txt','test_us.txt','test_ca.txt','test_ru.txt']\n",
        "list_dataset_test_accent=['Österreichisches Deutsch','Britisches Deutsch','Italienisch Deutsch','Alemannische Färbung,Schweizer Standart Deutsch',\n",
        "'Französisch Deutsch','Niederländisch Deutsch','Schweizerdeutsch','Deutschland Deutsch','Amerikanisches Deutsch','Kanadisches Deutsch','Russisch Deutsch']\n",
        "\n",
        "data_dict_accent_duration  = dict(zip( list_dataset_test_, list_dataset_test_accent))  \n",
        "\n",
        "# create an empty set to store the words that meet all 11 accents\n",
        "\n",
        "\n",
        "accent_long_list=[]\n",
        " \n",
        "\n",
        "### here is the required_word\n",
        "# required_word=\"Start\"\n",
        "# required_word=input('Insert a word to test it please? ')\n",
        "newfile=0\n",
        "\n",
        "\n",
        "# dict_audiofilename_transcript_accent=[]\n",
        "# To find out the Audio file's Accent\n",
        "list_test_accent_txt_values=[]\n",
        "list_test_accent_txt_keys=[]\n",
        "list_test_file=[]\n",
        "list_accent_long=[]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  Dict_results = json.load(open('results.json'))\n",
        "  for test_file in Dict_results:\n",
        "    # print(test_file)\n",
        "    list_test_accent_txt_values_temp = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
        "    list_test_accent_txt_keys_temp=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
        "    list_test_file_temp=[test_file for v in Dict_results[test_file].values()]\n",
        "\n",
        "# creat a Dataframe called  dataset_audiofilename_transcript_accent contains all audiofilename and thier 'transcript' and 'test_file' /Accent\n",
        "    list_test_accent_txt_values.extend(list_test_accent_txt_values_temp)\n",
        "    list_test_accent_txt_keys.extend(list_test_accent_txt_keys_temp)\n",
        "    list_test_file.extend(list_test_file_temp)\n",
        "    keys=['audiofilename','transcript','test_file']\n",
        "    trans_dict_test_file_result = dict(zip(keys,[list_test_accent_txt_keys, list_test_accent_txt_values,list_test_file]))\n",
        "    \n",
        "dataset_audiofilename_transcript_accent = pd.DataFrame(trans_dict_test_file_result)\n",
        " \n",
        "# Tokenize the sentences in the transcripts column using the sent_tokenize function from the nltk library. This will create a list of sentences.\n",
        "sentences = dataset_audiofilename_transcript_accent['transcript'].apply(sent_tokenize)\n",
        "\n",
        "# Tokenize the words in each sentence using the word_tokenize function from the nltk library. This will create a list of words for each sentence.\n",
        "words = sentences.apply(lambda x: [word_tokenize(sentence) for sentence in x])\n",
        "\n",
        "# Flatten the list of words so that you have a single list of all words in the transcripts column.\n",
        "all_words = [word for sentence in words for word_list in sentence for word in word_list]\n",
        "\n",
        "# Use the Counter function from the collections library to count the occurrences of each word.\n",
        "from collections import Counter\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# Convert the word_counts object to a data frame using the pd.DataFrame function.\n",
        "word_counts_dataset_audiofilename_transcript_accent = pd.DataFrame.from_dict(word_counts, orient='index', columns=['count'])\n",
        "\n",
        "# Sort the data frame by the count column in descending order.\n",
        "word_counts_dataset_audiofilename_transcript_accent = word_counts_dataset_audiofilename_transcript_accent.sort_values('count', ascending=False)\n",
        "\n",
        "print('Count the number of occurrences of each word over the sentences located in the transcripts column of a data frame:')\n",
        "print(word_counts_dataset_audiofilename_transcript_accent)\n",
        "word_counts_dataset_audiofilename_transcript_accent.to_csv('number_of_occurrences_of_each_word.csv', index=True)"
      ],
      "metadata": {
        "id": "KIRokGFa01HZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRefw7qIRF9y"
      },
      "source": [
        "###<font color=\"00ff00\">  **Normalize Attributions**</font>\n",
        "<font color=white> **Normalize Attributions**</font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdJaXI1IRF9s",
        "outputId": "2acf1abd-d767-48d3-ac6e-2ccc48aecc10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************print Labels************************\n",
            "label: client_id\n",
            "label: path\n",
            "label: sentence\n",
            "label: up_votes\n",
            "label: down_votes\n",
            "label: age\n",
            "label: gender\n",
            "label: accents\n",
            "label: locale\n",
            "label: segment\n",
            "*********************print Contents**********************\n",
            "content: 6         03ac3eb87717f430b8a64228e61b5829cf6187f790c0fd...\n",
            "21        0b8442069d5bdd1f2a891edc5cae7c92471e35742da54a...\n",
            "26        0df96a055c391517acf584f64f74df3e5356de0c14a6c8...\n",
            "45        1aabab5972b13f76cd0ae98088be9d79c3bfbb30fd60a3...\n",
            "51        1e44e03d919c81cb3b1e8a1c5d494e864607631e690d83...\n",
            "                                ...                        \n",
            "793063    372293e65cdab88771e028a4351651ab2eff64438ddafc...\n",
            "793064    372293e65cdab88771e028a4351651ab2eff64438ddafc...\n",
            "793065    372293e65cdab88771e028a4351651ab2eff64438ddafc...\n",
            "793066    372293e65cdab88771e028a4351651ab2eff64438ddafc...\n",
            "793067    372293e65cdab88771e028a4351651ab2eff64438ddafc...\n",
            "Name: client_id, Length: 539234, dtype: object\n",
            "content: 6         common_voice_de_18520278.mp3\n",
            "21        common_voice_de_19625120.mp3\n",
            "26        common_voice_de_26888041.mp3\n",
            "45        common_voice_de_19756404.mp3\n",
            "51        common_voice_de_18205461.mp3\n",
            "                      ...             \n",
            "793063    common_voice_de_32911655.mp3\n",
            "793064    common_voice_de_32911638.mp3\n",
            "793065    common_voice_de_32911641.mp3\n",
            "793066    common_voice_de_32911661.mp3\n",
            "793067    common_voice_de_32911666.mp3\n",
            "Name: path, Length: 539234, dtype: object\n",
            "content: 6                                Was solls, ich bin bereit.\n",
            "21        Ein großer Teil der Conciergerie wird heute fü...\n",
            "26        Wenn nicht, dann legt man sie irgendwo hin, wo...\n",
            "45        Sie liegt im Osten des Landes, an der Grenze z...\n",
            "51            Meine Lieblingsfarbe ist schwarz, sagte Lola.\n",
            "                                ...                        \n",
            "793063    Gegen Bezahlung posierte sie für Fotos und gab...\n",
            "793064    Zur Folgesaison wechselte er fest in die Niede...\n",
            "793065    Er ist auf die Stile Schmetterling und Lagen s...\n",
            "793066                             Vieles wurde exportiert.\n",
            "793067     Bei Punktgleichheit zählt der direkte Vergleich.\n",
            "Name: sentence, Length: 539234, dtype: object\n",
            "content: 6         2\n",
            "21        3\n",
            "26        4\n",
            "45        2\n",
            "51        2\n",
            "         ..\n",
            "793063    3\n",
            "793064    6\n",
            "793065    3\n",
            "793066    6\n",
            "793067    3\n",
            "Name: up_votes, Length: 539234, dtype: int64\n",
            "content: 6         1\n",
            "21        2\n",
            "26        0\n",
            "45        0\n",
            "51        0\n",
            "         ..\n",
            "793063    0\n",
            "793064    0\n",
            "793065    0\n",
            "793066    0\n",
            "793067    0\n",
            "Name: down_votes, Length: 539234, dtype: int64\n",
            "content: 6          thirties\n",
            "21         fourties\n",
            "26         twenties\n",
            "45         thirties\n",
            "51        seventies\n",
            "            ...    \n",
            "793063      fifties\n",
            "793064      fifties\n",
            "793065      fifties\n",
            "793066      fifties\n",
            "793067      fifties\n",
            "Name: age, Length: 539234, dtype: object\n",
            "content: 6           male\n",
            "21         other\n",
            "26        female\n",
            "45          male\n",
            "51          male\n",
            "           ...  \n",
            "793063      male\n",
            "793064      male\n",
            "793065      male\n",
            "793066      male\n",
            "793067      male\n",
            "Name: gender, Length: 539234, dtype: object\n",
            "content: 6                                          Russisch Deutsch\n",
            "21                                      Französisch Deutsch\n",
            "26                                         Russisch Deutsch\n",
            "45                                         Schweizerdeutsch\n",
            "51                                      Deutschland Deutsch\n",
            "                                ...                        \n",
            "793063    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
            "793064    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
            "793065    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
            "793066    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
            "793067    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
            "Name: accents, Length: 539234, dtype: object\n",
            "content: 6         de\n",
            "21        de\n",
            "26        de\n",
            "45        de\n",
            "51        de\n",
            "          ..\n",
            "793063    de\n",
            "793064    de\n",
            "793065    de\n",
            "793066    de\n",
            "793067    de\n",
            "Name: locale, Length: 539234, dtype: object\n",
            "content: 6         NaN\n",
            "21        NaN\n",
            "26        NaN\n",
            "45        NaN\n",
            "51        NaN\n",
            "         ... \n",
            "793063    NaN\n",
            "793064    NaN\n",
            "793065    NaN\n",
            "793066    NaN\n",
            "793067    NaN\n",
            "Name: segment, Length: 539234, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "tsv_data = pd.read_csv('validated.tsv', sep='\\t')\n",
        "tsv_data.drop(tsv_data[(tsv_data['accents'].isna())].index, inplace=True)\n",
        "tsv_data\n",
        "print('*******************print Labels************************')\n",
        "\n",
        "for label, content in tsv_data.items():\n",
        "    print(f'label: {label}')\n",
        "    #print(f'content: {content}', sep='\\n')\n",
        "\n",
        "print('*********************print Contents**********************')\n",
        "\n",
        "for label, content in tsv_data.items():\n",
        "    #print(f'label: {label}')\n",
        "    print(f'content: {content}', sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tsv_data['common_voice_de_18568843']['accents']"
      ],
      "metadata": {
        "id": "tGj0nNAKbo2C"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fokKuR1jR6yA",
        "outputId": "8eb003e2-3b07-4a73-d4d6-a2cbd3261844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6                                          Russisch Deutsch\n",
              "21                                      Französisch Deutsch\n",
              "26                                         Russisch Deutsch\n",
              "45                                         Schweizerdeutsch\n",
              "51                                      Deutschland Deutsch\n",
              "                                ...                        \n",
              "793063    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
              "793064    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
              "793065    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
              "793066    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
              "793067    Nordrhein-Westfalen,Bundesdeutsch, Hochdeutsch...\n",
              "Name: accents, Length: 539234, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "tsv_data['accents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCil0nxzRF9z",
        "outputId": "1ee05bdf-2f70-418d-9d95-5cc81a78aad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['schreib ihr halt ein paar liebe worte rein']\n"
          ]
        }
      ],
      "source": [
        "# Dipslay the transcript of an Audio file\n",
        "# file_meta['test_at.txt']\n",
        "print(dataset_trans[dataset_trans['audio_filepath'] == 'common_voice_de_18946081'].transcript.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### find the Audio file name\n",
        "trans_dict['schreib ihr halt ein paar liebe worte rein']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDAxU3jFM0pS",
        "outputId": "7577f53a-c47a-40e1-dffa-d1e36e96d6d2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['common_voice_de_18946081', 'common_voice_de_18568843']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path1 = 'folder1'\n",
        "path2 = 'folder2'\n",
        "filename = 'file.txt'\n",
        "\n",
        "# Concatenating the path components using os.sep.join()\n",
        "full_path = os.sep.join([path1, path2, filename] )\n",
        "print(full_path) # Output: folder1\\folder2\\file.txt (on Windows)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUjPZhC1VpaT",
        "outputId": "336871f5-4fe3-4c44-ac34-fa692bad1c3f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder1/folder2/file.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9pHzFVJi8TPx",
        "outputId": "da103b4d-dc4b-4d3a-aa87-6f30c3ac3be5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test111/*.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "path_file = \"{}{}{}\".format('/content/test111', os.sep, '*.txt')\n",
        "path_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "72uRRZ2s-rfz",
        "outputId": "721d70ee-fd73-4484-f306-8ce38057c4aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test555/*.txt.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "path_file: str = \"{}/{}\".format('/content/test555', '*.txt.py') \n",
        "path_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8tfT7eERF9z"
      },
      "source": [
        "###<font color=\"00ff00\">  **Preparing the data Audio files:**</font>\n",
        "<font color=white> **Convert the data Audio MP3 files to WAV files :**</font> "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title convert the mp3 data Audio files to Wav Audio files\n",
        "! pip install pydub\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "if not os.path.exists('audio_mp3_files_De'):\n",
        "    os.mkdir('audio_mp3_files_De')\n",
        "! cp  /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/ASR-Accent-Analysis-De/audio_mp3_files_De/*.* /content/audio_mp3_files_De\n",
        "\n",
        "# Set the path to the folder containing the MP3 files\n",
        "mp3_path = \"/content/audio_mp3_files_De/*.mp3\"\n",
        "\n",
        "# Use glob to get a list of all MP3 files in the folder\n",
        "mp3_files = glob.glob(mp3_path)\n",
        "\n",
        "# Create an empty list to store the file names\n",
        "file_names = []\n",
        "\n",
        "# # Loop through the list of MP3 files and add the file names to the list\n",
        "# for file_path in mp3_files:\n",
        "#     file_name = os.path.basename(file_path)\n",
        "#     file_names.append(file_name)\n",
        "\n",
        "# Set the path to the folder where the converted WAV files will be saved\n",
        "wav_path = \"/content/audio_wav_files_De\"\n",
        "\n",
        "# Create the folder to store the WAV files, if it doesn't exist\n",
        "if not os.path.exists(wav_path):\n",
        "    os.makedirs(wav_path)\n",
        "\n",
        "# Loop through the list of MP3 files\n",
        "for mp3_file in mp3_files:\n",
        "    # Load the MP3 file using pydub\n",
        "    audio = AudioSegment.from_mp3(mp3_file)\n",
        "\n",
        "    # Set the path and filename for the output WAV file\n",
        "    wav_file = os.path.join(wav_path, os.path.splitext(os.path.basename(mp3_file))[0] + \".wav\")\n",
        "\n",
        "    # Export the audio to WAV format\n",
        "    audio.export(wav_file, format=\"wav\")\n",
        "print('Conv')    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voJ8oMpyZ7eh",
        "outputId": "65698c87-1f63-439c-c794-624c5fa0b4a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_conformer_transducer_large/versions/1.6.0/zip -O stt_de_conformer_transducer_large_1.6.0.zip"
      ],
      "metadata": {
        "id": "n_2HbebLSyJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABe2g_dZRF9z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title convert the mp3 data Audio files to Wav Audio files\n",
        "! pip install pydub\n",
        "! apt-get install ffmpeg\n",
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "if not os.path.exists('audio_mp3_files_De'):\n",
        "    os.mkdir('audio_mp3_files_De')\n",
        "! cp  /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/ASR-Accent-Analysis-De/audio_mp3_files_De/*.* /content/audio_mp3_files_De\n",
        "\n",
        "\n",
        "\n",
        "# Set the path to the folder containing the MP3 files\n",
        "mp3_path = \"/content/audio_mp3_files_De/*.mp3\"\n",
        "\n",
        "# Use glob to get a list of all MP3 files in the folder\n",
        "mp3_files = glob.glob(mp3_path)\n",
        "\n",
        "# Create an empty list to store the file names\n",
        "file_names = []\n",
        "\n",
        "# # Loop through the list of MP3 files and add the file names to the list\n",
        "# for file_path in mp3_files:\n",
        "#     file_name = os.path.basename(file_path)\n",
        "#     file_names.append(file_name)\n",
        "\n",
        "# Set the path to the folder where the converted WAV files will be saved\n",
        "wav_path = \"/content/audio_wav_files_De\"\n",
        "\n",
        "# Create the folder to store the WAV files, if it doesn't exist\n",
        "if not os.path.exists(wav_path):\n",
        "    os.makedirs(wav_path)\n",
        "\n",
        "# Loop through the list of MP3 files\n",
        "for mp3_file in mp3_files:\n",
        "    # Load the MP3 file using pydub\n",
        "    audio = AudioSegment.from_mp3(mp3_file)\n",
        "\n",
        "    # Set the path and filename for the output WAV file\n",
        "    wav_file = os.path.join(wav_path, os.path.splitext(os.path.basename(mp3_file))[0] + \".wav\")\n",
        "\n",
        "    # Export the audio to WAV format\n",
        "    audio.export(wav_file, format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title display Audio (Wav) files\n",
        "import librosa\n",
        "import glob\n",
        "from IPython.display import Audio\n",
        "import IPython.display as ipd\n",
        "\n",
        "i=0\n",
        "\n",
        "# Set the path to the folder containing the WAV files\n",
        "wav_path = \"/content/audio_wav_files_De\"\n",
        "\n",
        "# Use glob to get a list of all WAV files in the folder\n",
        "wav_files = glob.glob(wav_path + \"/*.wav\")\n",
        "\n",
        "\n",
        "# Loop through the list of WAV files and play each file\n",
        "for example_file in wav_files:\n",
        "\n",
        "    # Load the audio file using librosa\n",
        "    audio, sample_rate = librosa.load(example_file)\n",
        "\n",
        "    # Create an IPython.display.Audio object and play the audio\n",
        "    # Load and listen to the audio file\n",
        "    audio_display = Audio(audio, rate=sample_rate)\n",
        "    display(audio_display)\n",
        "    # ipd.Audio(example_file, rate=sample_rate)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "S1LSo0T0TKwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Waveform_of_Audio_Examples\n",
        "%matplotlib inline\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import glob\n",
        "from IPython.display import Audio\n",
        "import IPython.display as ipd\n",
        "\n",
        "\n",
        "i=0\n",
        "\n",
        "# Set the path to the folder containing the WAV files\n",
        "wav_path = \"/content/audio_wav_files_De\"\n",
        "\n",
        "# Use glob to get a list of all WAV files in the folder\n",
        "wav_files = glob.glob(wav_path + \"/*.wav\")\n",
        "\n",
        "# Loop through the list of WAV files and play each file\n",
        "for example_file in wav_files:\n",
        "\n",
        "    # Load the audio file using librosa\n",
        "    audio, sample_rate = librosa.load(example_file)\n",
        "\n",
        "    # Plot the mel spectrogram of our sample in figure of 12 sectors to fit 11 German Accent\n",
        "    figure_Waveform_of_Audio_Example=plt.figure(12,figsize=(25,25))  \n",
        "\n",
        "    if i <= 6:\n",
        "      ax_Waveform_of_Audio_Example_123=figure_Waveform_of_Audio_Example.add_subplot(3,4,i+1)\n",
        "      i+=1\n",
        "    else:\n",
        "      break\n",
        "    # Plot our example audio file's waveform\n",
        "    plt.rcParams['figure.figsize'] = (15,7)\n",
        "    plt.title('Waveform of Audio Example')\n",
        "    plt.ylabel('Amplitude')\n",
        "    _ = librosa.display.waveshow(audio)\n",
        "plt.savefig('Waveform_of_Audio_Examples.png',facecolor='white')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ucbtxvGATTw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Audio Spectrogram\n",
        "import numpy as np \n",
        "\n",
        "i=0\n",
        "\n",
        "# Set the path to the folder containing the WAV files\n",
        "wav_path = \"/content/audio_wav_files_De\"\n",
        "\n",
        "# Use glob to get a list of all WAV files in the folder\n",
        "wav_files = glob.glob(wav_path + \"/*.wav\")\n",
        "\n",
        "# Loop through the list of WAV files and play each file\n",
        "for example_file in wav_files:\n",
        "\n",
        "    # Load the audio file using librosa\n",
        "    audio, sample_rate = librosa.load(example_file)\n",
        "\n",
        "\n",
        "    # Plot the mel spectrogram of our sample in figure of 12 sectors to fit 11 German Accent\n",
        "    figure_Audio_Spectrogram=plt.figure(12,figsize=(25,25))  \n",
        "\n",
        "    if i <= 6:\n",
        "      ax_Audio_Spectrogram_123=figure_Audio_Spectrogram.add_subplot(3,4,i+1)\n",
        "      i+=1\n",
        "    else:\n",
        "      break\n",
        "\n",
        "\n",
        "    # Get spectrogram using Librosa's Short-Time Fourier Transform (stft)\n",
        "    spec = np.abs(librosa.stft(audio))\n",
        "    spec_db = librosa.amplitude_to_db(spec, ref=np.max)  # Decibels\n",
        "\n",
        "    # Use log scale to view frequencies\n",
        "    librosa.display.specshow(spec_db, y_axis='log', x_axis='time')\n",
        "    plt.colorbar()\n",
        "    plt.title('Audio Spectrogram');\n",
        "plt.savefig('Audio_Spectrogram.png',facecolor='white')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H8As0vR0TZIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mel Spectrogram\n",
        "import numpy as np \n",
        "\n",
        "i=0\n",
        "\n",
        "# Set the path to the folder containing the WAV files\n",
        "wav_path = \"/content/audio_wav_files_De\"\n",
        "\n",
        "# Use glob to get a list of all WAV files in the folder\n",
        "wav_files = glob.glob(wav_path + \"/*.wav\")\n",
        "\n",
        "# Loop through the list of WAV files and play each file\n",
        "for example_file in wav_files:\n",
        "\n",
        "    # Load the audio file using librosa\n",
        "    audio, sample_rate = librosa.load(example_file)\n",
        "\n",
        "    # Plot the mel spectrogram of our sample in figure of 12 sectors to fit 11 German Accent\n",
        "    figure_Audio_Spectrogram=plt.figure(12,figsize=(25,25))  \n",
        "    if i <= 6:\n",
        "      ax_Audio_Spectrogram_123=figure_Audio_Spectrogram.add_subplot(3,4,i+1)\n",
        "      i+=1\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    # Plot the mel spectrogram of our sample\n",
        "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    librosa.display.specshow(\n",
        "        mel_spec_db, x_axis='time', y_axis='mel')\n",
        "    plt.colorbar()\n",
        "    plt.title('Mel Spectrogram');\n",
        "\n",
        "plt.savefig('Mel_Spectrogram.png',facecolor='white')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kNPEIPDjTZFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Normalize Attributions "
      ],
      "metadata": {
        "id": "Pjob5vdlWkgS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMfHndwcWmoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T77b4UAGRF9s"
      },
      "outputs": [],
      "source": [
        "\n",
        "# my_data/common-final-file-info.json==>> results-AOE.json\n",
        "with open('results-AOE.json', 'r', encoding=\"utf-8\") as j:\n",
        "\tfile_meta_json = json.load(j)\n",
        " \n",
        "\n",
        "# Create an empty dictionary\n",
        "file_meta = {}\n",
        "\n",
        "# Loop through each key-value pair in the JSON data\n",
        "for accent, audio_data in file_meta_json.items():\n",
        "\t# Loop through each audio file in the audio data\n",
        "\t# print(audio_data)\n",
        "\tfor audio_file, info in audio_data.items():\n",
        "\t\t# print(audio_file)\t\n",
        "\t\tinfo['audio']=re.split(r'[/|/|.]',audio_file)[9] \n",
        "\n",
        "\t\t# print(info)\n",
        "\t\t# Get the transcript from the reference field\n",
        "\t\ttranscript = info['reference']\n",
        "\t\t# Create a new inner dictionary with the accent and transcript\n",
        "\t\tinner_dict = {'accent': accent, 'transcript': transcript}\n",
        "\t\t# # Add the inner dictionary to the file_meta dictionary\n",
        "\t\tfile_meta[info['audio']] = inner_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_meta['common_voice_de_17298952']['accent']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qu8eHbm8jX18",
        "outputId": "fdb20528-f3b0-4993-9e1f-a8abef0aa749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_ru.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_meta['common_voice_de_17298952']['transcript']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KGiS18AnrkJE",
        "outputId": "db966505-20db-4f90-87f7-9813981074d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'können sie ein konkretes beispiel nennen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_meta['common_voice_de_17298952'].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXoDG3hkVRo6",
        "outputId": "70085bc8-5ae9-4a7a-fb0c-9df8d706983d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['accent', 'transcript'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################## show the first 5 rows of the dictionary trans_dict ##################################\n",
        "from itertools import islice\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "n_items = take(5, file_meta.items())\n",
        "n_items \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raPbqMf_rvT0",
        "outputId": "9f65dc33-c812-4d7e-cb83-7eb242f3dba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('common_voice_de_31449916',\n",
              "  {'accent': 'test_at.txt',\n",
              "   'transcript': 'er ist nach eustache de saint pierre der bekannteste der gruppe'}),\n",
              " ('common_voice_de_19730674',\n",
              "  {'accent': 'test_at.txt',\n",
              "   'transcript': 'eine erste kleinformatige vorstudie in bleistift findet sich in einem von kellers skizzenbüchern'}),\n",
              " ('common_voice_de_19703888',\n",
              "  {'accent': 'test_at.txt',\n",
              "   'transcript': 'er blieb ohne erfolg und lag in ständigem streit mit den österreichischen generälen'}),\n",
              " ('common_voice_de_18507972',\n",
              "  {'accent': 'test_at.txt',\n",
              "   'transcript': 'mein garten ist teil eines kleingartenvereins'}),\n",
              " ('common_voice_de_24131267',\n",
              "  {'accent': 'test_at.txt',\n",
              "   'transcript': 'was habe ich damals für einen unsinn geträumt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijpo-CE6RF9z"
      },
      "outputs": [],
      "source": [
        "def get_norm_attr(index_dict):\n",
        "    norm_dict = {}\n",
        "    for key in index_dict.keys():\n",
        "        norm_dict[key] = index_dict[key]/np.sum(index_dict[key])\n",
        "        np.set_printoptions(precision=4)\n",
        "        #print(norm_dict[key])\n",
        "        #break\n",
        "    return norm_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmxhTbhKRF9z"
      },
      "source": [
        "###<font color=white> **Fetching frame allignmnets from the meta-data (using gentle)**</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP1ZlgF7RF90"
      },
      "outputs": [],
      "source": [
        "def get_frame_allignment(file, input_size):\n",
        "    alligned = []\n",
        "    spec_stride = 0.01\n",
        "    window_size = 0.02\n",
        "    times = file_meta[file]['end_times']\n",
        "    last_idx = 0\n",
        "    for i in range(input_size):\n",
        "        frame_idx = i\n",
        "        window_start = frame_idx*spec_stride\n",
        "        window_mid = window_start + (window_size/2)\n",
        "        alligned_phone = 'na'\n",
        "        for j in range(len(times)):\n",
        "            if (window_mid < times[j]):\n",
        "                alligned_phone = file_meta[file]['phones'][j]\n",
        "                break\n",
        "        #assert alligned_phone != 'na', \"Failed to fetch allignment\"\n",
        "        if(alligned_phone != 'na'):\n",
        "            alligned.append(alligned_phone)\n",
        "            last_idx = i\n",
        "    pause_start = 0\n",
        "    pause_end = len(alligned)\n",
        "    for i in range(len(alligned)):\n",
        "        if(alligned[i] != 'pause'):\n",
        "            break\n",
        "        pause_start = i\n",
        "    \n",
        "    for i in range(len(alligned)-1,-1,-1):\n",
        "        if(alligned[i] != 'pause'):\n",
        "            break\n",
        "        pause_end = i\n",
        "        \n",
        "    #print(last_idx)\n",
        "    #print(pause_start, pause_end)\n",
        "    return alligned, pause_start +1, pause_end\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBqnV_cZ9IPf"
      },
      "outputs": [],
      "source": [
        "##### find the Audio file name\n",
        "trans_dict['schreib ihr halt ein paar liebe worte rein']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_meta['common_voice_de_18568843']"
      ],
      "metadata": {
        "id": "cjDqCbFzbJ3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(list_test_accent_txt_values)"
      ],
      "metadata": {
        "id": "3XxXLlgqUJ34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbc2aISXRF90"
      },
      "source": [
        "###<font color=white> **Visualizing (signed) attributions**</font>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3RuE54JRF90"
      },
      "outputs": [],
      "source": [
        "# if __name__ == \"__main__\":\n",
        "#   Dict_results = json.load(open('results.json'))\n",
        "#   for accent in Dict_results:\n",
        "#     list_test_accent_txt_values = [v[\"reference\"] for v in Dict_results[accent].values()]\n",
        "\n",
        "for file in trans_dict['schreib ihr halt ein paar liebe worte rein']:\n",
        "    try:\n",
        "        #file = 'common_voice_de_18946081' for file in ['schreib ihr halt ein paar liebe worte rein']:\n",
        "        Fs, wav = wavfile.read('/content/audio_wav_files_De/{}.wav'.format(file_meta[file]['test_at.txt'],file))\n",
        "        display(Audio(wav, rate=Fs))\n",
        "        with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "            file_attr = pickle.load(j)\n",
        "        print(file_attr['output'], file_meta[file]['test_at.txt'])\n",
        "        print(list(file_attr['attr dict'].keys()))\n",
        "        normalized_attr = get_norm_attr(file_attr['attr dict'])\n",
        "        keys = list(normalized_attr.keys())\n",
        "        input_size = len(file_attr['attr dict'][list(file_attr['attr dict'].keys())[0]]) # calculate properly once\n",
        "        buffer = 10\n",
        "    #print(get_frame_allignment(file,input_size))\n",
        "    #     with np.printoptions(precision=4, suppress=True):\n",
        "    #         print(normalized_attr[1][:291])\n",
        "        plot_vertical = False\n",
        "        idx = 0\n",
        "        if(plot_vertical):\n",
        "            fig = plt.figure(figsize = (1,35))\n",
        "            print(get_frame_allignment(file, input_size))\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            sns.heatmap(np.expand_dims(normalized_attr[1][:actual_size], axis = 1),annot = np.expand_dims(allignments, axis = 1), fmt=\"\", cmap='RdBu')\n",
        "            #plt.yticks(rotation=) \n",
        "            #plt.yticks(range(allignments.shape[0]),list(allignments))\n",
        "            plt.show()\n",
        "        else:\n",
        "            \n",
        "            fig = plt.figure(figsize = (37,1))\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            #actual_size = len(allignments)\n",
        "            \n",
        "            print('for',file_attr['output'][keys[idx]])\n",
        "            sns.heatmap(np.expand_dims(normalized_attr[keys[idx]][p_start - buffer:p_end + buffer], axis = 0), fmt=\"\", cmap='RdBu')\n",
        "            #plt.yticks(rotation=) \n",
        "            modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "            #phone_centres = []\n",
        "            phone_labels = [x[0] for x in groupby(modified_allignments)]\n",
        "            len_list = [len(list(x[1])) for x in groupby(modified_allignments)]\n",
        "            idx_list = [0]\n",
        "            ticks_list = []\n",
        "            for l in len_list:\n",
        "                ticks_list.append(idx_list[-1] + l//2)\n",
        "                idx_list.append(idx_list[-1] + l)\n",
        "                \n",
        "           \n",
        "            plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "            \n",
        "            for j in idx_list:\n",
        "                plt.axvline(x=j, color='w', linestyle='-', linewidth=2.5)\n",
        "                plt.axvline(x=j, color='k', linestyle='--', linewidth=2.5)\n",
        "                \n",
        "                \n",
        "                \n",
        "            plt.show()\n",
        "    #break\n",
        "    except:\n",
        "        print('failed for file : {}'.format(file))\n",
        "        continue\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_a-88MBRF90"
      },
      "source": [
        "###<font color=\"00ff00\">  **Visualizing (modulus/magnitude) attributions**</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xURhYJzBRF92"
      },
      "source": [
        "###<font color=white> Generate **|*Input.Gradient*|** Attributution at grapheme-level</font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kik3GLKRF92"
      },
      "outputs": [],
      "source": [
        "#for file in trans_dict[\"I'm going to them.\"]:\n",
        "def inp_grad_grapheme(file, idx):\n",
        "    try:\n",
        "        #file = 'common_voice_en_110121'\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "        with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "            file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "#         print(list(file_attr['attr dict'].keys()))\n",
        "        normalized_attr = get_norm_attr(file_attr['attr dict'])\n",
        "        keys = list(normalized_attr.keys())\n",
        "        input_size = len(file_attr['attr dict'][list(file_attr['attr dict'].keys())[0]]) # calculate properly once\n",
        "        buffer = 10\n",
        "    #print(get_frame_allignment(file,input_size))\n",
        "    #     with np.printoptions(precision=4, suppress=True):\n",
        "    #         print(normalized_attr[1][:291])\n",
        "        plot_vertical = False\n",
        "        #idx = 0\n",
        "        \n",
        "        if(plot_vertical):\n",
        "            fig = plt.figure(figsize = (1,35))\n",
        "            print(get_frame_allignment(file, input_size))\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            sns.heatmap(np.expand_dims(normalized_attr[1][:actual_size], axis = 1),annot = np.expand_dims(allignments, axis = 1), fmt=\"\", cmap='RdBu')\n",
        "            #plt.yticks(rotation=) \n",
        "            #plt.yticks(range(allignments.shape[0]),list(allignments))\n",
        "            plt.show()\n",
        "        else:\n",
        "            \n",
        "            fig = plt.figure(figsize = (37,1))\n",
        "            #print(allignments)\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            #actual_size = len(allignments)\n",
        "            \n",
        "            print('for',file_attr['output'][keys[idx]])\n",
        "            sns.heatmap(np.expand_dims(np.abs(normalized_attr[keys[idx]][p_start - buffer:p_end + buffer])/np.sum(np.abs(normalized_attr[keys[idx]][p_start - buffer:p_end + buffer])), axis = 0), fmt=\"\", cmap='Blues')\n",
        "            #plt.yticks(rotation=) \n",
        "            modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "            phone_labels = [x[0] for x in groupby(modified_allignments)]\n",
        "            len_list = [len(list(x[1])) for x in groupby(modified_allignments)]\n",
        "            idx_list = [0]\n",
        "            ticks_list = []\n",
        "            for l in len_list:\n",
        "                ticks_list.append(idx_list[-1] + l//2)\n",
        "                idx_list.append(idx_list[-1] + l)\n",
        "                \n",
        "            #ticks_list.append((idx_list[-1] + len(modified_allignments))//2)   \n",
        "            \n",
        "            plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "            \n",
        "            for j in idx_list:\n",
        "                plt.axvline(x=j, color='w', linestyle='-', linewidth=2.5)\n",
        "                plt.axvline(x=j, color='k', linestyle='--', linewidth=2.5)\n",
        "            plt.show()\n",
        "                \n",
        "    #break\n",
        "    except:\n",
        "        print('failed for file : {}'.format(file))\n",
        "        #continue\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dc1KGljRF92"
      },
      "source": [
        "##### Helper functions for word-level allignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsdRogv4RF93"
      },
      "outputs": [],
      "source": [
        "def get_space(inp):\n",
        "    spaces = []\n",
        "    for idx, val in enumerate(inp):\n",
        "        if(val == ' '): spaces.append(idx)\n",
        "    return spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKtlqHgPRF93"
      },
      "outputs": [],
      "source": [
        "def get_words(test_list, split_list,spaces):\n",
        "    temp = zip(chain([0], split_list), chain(split_list, [None])) \n",
        "    res = list(test_list[i : j] for i, j in temp) \n",
        "    #print(res)\n",
        "    final_res = []\n",
        "    for l in res:\n",
        "        if(l[0] in spaces):\n",
        "            final_res.append([l[0]])\n",
        "            final_res.append(l[1:])\n",
        "        else: \n",
        "            final_res.append(l)\n",
        "    #print(final_res)\n",
        "    return final_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzNBcp8BRF93"
      },
      "outputs": [],
      "source": [
        "def get_words_wo_space(test_list, split_list,spaces):\n",
        "    temp = zip(chain([0], split_list), chain(split_list, [None])) \n",
        "    res = list(test_list[i : j] for i, j in temp) \n",
        "    #print(res)\n",
        "    final_res = []\n",
        "    for l in res:\n",
        "        if(l[0] in spaces):\n",
        "            final_res.append([l[0]])\n",
        "            final_res.append(l[1:])\n",
        "        else: \n",
        "            final_res.append(l)\n",
        "    #print(final_res)\n",
        "    return final_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIsVxQ9JRF93"
      },
      "source": [
        "##### Generate **|*Input.Gradient*|** Attributution at word-level "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1T5YHOxRF93"
      },
      "outputs": [],
      "source": [
        "#for file in trans_dict[\"I'm going to them.\"]:\n",
        "def inp_grad_word(file, word_idx):\n",
        "    try:\n",
        "    #file = 'common_voice_en_110121'\n",
        "    #print(file)\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "        with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "            file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "\n",
        "    #         print(file_attr['output'].split(' '))\n",
        "        normalized_attr = get_norm_attr(file_attr['attr dict'])\n",
        "        keys = list(normalized_attr.keys())\n",
        "#         print(keys)\n",
        "        spaces = get_space(file_attr['output'])\n",
        "        indices = [keys.index(x) for x in spaces]\n",
        "        words = get_words(keys,indices, spaces)\n",
        "        input_size = len(file_attr['attr dict'][list(file_attr['attr dict'].keys())[0]]) # calculate properly once\n",
        "        buffer = 10\n",
        "        plot_vertical = False\n",
        "        #word_idx = 0\n",
        "\n",
        "        word_activation = np.sum(np.asarray([np.abs(normalized_attr[idx]) for idx in words[word_idx]] ), axis = 0)\n",
        "\n",
        "        if(plot_vertical):\n",
        "            fig = plt.figure(figsize = (1,35))\n",
        "            print(get_frame_allignment(file, input_size))\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            sns.heatmap(np.expand_dims(normalized_attr[1][:actual_size], axis = 1),annot = np.expand_dims(allignments, axis = 1), fmt=\"\", cmap='RdBu')\n",
        "\n",
        "            plt.show()\n",
        "        else:\n",
        "            str_list = []\n",
        "            for x in words[word_idx]:\n",
        "                str_list.append(file_attr['output'][x])\n",
        "\n",
        "\n",
        "            print(''.join(str_list))\n",
        "            fig = plt.figure(figsize = (37,1))\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            #actual_size = len(allignments)\n",
        "\n",
        "            sns.heatmap(np.expand_dims(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer]), axis = 0), fmt=\"\", cmap='Blues')\n",
        "            #plt.yticks(rotation=) [p_start - buffer:p_end + buffer]\n",
        "            modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "            phone_labels = [x[0] for x in groupby(modified_allignments)]\n",
        "            len_list = [len(list(x[1])) for x in groupby(modified_allignments)]\n",
        "            idx_list = [0]\n",
        "            ticks_list = []\n",
        "            for l in len_list:\n",
        "                ticks_list.append(idx_list[-1] + l//2)\n",
        "                idx_list.append(idx_list[-1] + l)\n",
        "\n",
        "\n",
        "            plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "\n",
        "            for j in idx_list:\n",
        "                plt.axvline(x=j, color='w', linestyle='-', linewidth=2.5)\n",
        "                plt.axvline(x=j, color='k', linestyle='--', linewidth=2.5)\n",
        "\n",
        "\n",
        "            plt.show()\n",
        "    \n",
        "    except:\n",
        "        print('failed for file : {}'.format(file))\n",
        "#         continue\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2g1iHBnRF93"
      },
      "source": [
        "##### Helper functions to compare WERs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaPkLxBcRF94"
      },
      "outputs": [],
      "source": [
        "def wer(s1, s2):\n",
        "        \"\"\"\n",
        "        Computes the Word Error Rate, defined as the edit distance between the\n",
        "        two provided sentences after tokenizing to words.\n",
        "        Arguments:\n",
        "            s1 (string): space-separated sentence\n",
        "            s2 (string): space-separated sentence\n",
        "        \"\"\"\n",
        "\n",
        "        # build mapping of words to integers\n",
        "        b = set(s1.split() + s2.split())\n",
        "        word2char = dict(zip(b, range(len(b))))\n",
        "\n",
        "        # map the words to a char array (Levenshtein packages only accepts\n",
        "        # strings)\n",
        "        w1 = [chr(word2char[w]) for w in s1.split()]\n",
        "        w2 = [chr(word2char[w]) for w in s2.split()]\n",
        "\n",
        "        return Lev.distance(''.join(w1), ''.join(w2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVwWCNSuRF94"
      },
      "outputs": [],
      "source": [
        "transcript_wer = {}\n",
        "#lm_wer = {}\n",
        "accent_lm_wer = {x: [] for x in ['us', 'indian','african','canada','australia','england','scotland']}\n",
        "accent_wer = {x: [] for x in ['us', 'indian','african','canada','australia','england','scotland']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHhc6kQrRF94"
      },
      "outputs": [],
      "source": [
        "with open('wers.pickle', 'rb') as l:\n",
        "    lm_wer = pickle.load(l)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPMksaviRF94"
      },
      "outputs": [],
      "source": [
        "for transcript in transcripts:\n",
        "    transcript_ = transcript.strip().upper()\n",
        "    wer_dict = {}\n",
        "\n",
        "    valid_punctuation = string.punctuation.replace(\"'\",\"\")\n",
        "    processed_transcript = transcript_.translate(str.maketrans({a:None for a in valid_punctuation }))\n",
        "    #print(processed_transcript)       \n",
        "    for file in trans_dict[transcript]:\n",
        "        try:\n",
        "            with open('attribution/{}.pickle'.format(file), 'rb') as j:\n",
        "                file_attr = pickle.load(j)\n",
        "            accent = file_meta[file]['accent']\n",
        "            \n",
        "            #print(accent)\n",
        "            output = file_attr['output'].replace('_', '')\n",
        "            #print(output)\n",
        "            num_tokens = len(processed_transcript.split())\n",
        "            wer_ = 100*wer(processed_transcript, output)/num_tokens\n",
        "            wer_dict[accent] = wer_\n",
        "            accent_wer[accent].append(wer_)\n",
        "            accent_lm_wer[accent].append(lm_wer[file]['wer'])\n",
        "            \n",
        "        except:\n",
        "            continue\n",
        "        \n",
        "    \n",
        "    transcript_wer[transcript] = wer_dict\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVkC9f-tRF94"
      },
      "outputs": [],
      "source": [
        "print('accent','|', 'greedy','|', 'lm rescored','|', 'num of files')\n",
        "for key in accent_wer.keys():\n",
        "    print(key,'|', np.asarray(accent_wer[key]).mean(),'|', np.asarray(accent_lm_wer[key]).mean(),'|', len(accent_wer[key]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpGBXs5ARF94"
      },
      "outputs": [],
      "source": [
        "#get_colour = {'us':'k', 'indian':'g','african':'b','canada':'r','australia':'c','england':'m','scotland':'y'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEAn4dp0RF94"
      },
      "source": [
        "##### Generate **|*Gradient*|** Attribution at grapheme-level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fszXWxWzRF95"
      },
      "outputs": [],
      "source": [
        "#for file in trans_dict[\"I'm going to them.\"]:\n",
        "def grad_grapheme(file, idx):\n",
        "    try:\n",
        "        #file = 'common_voice_en_110121'\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "        with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "            file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "#         print(list(file_attr['grad_dict'].keys()))\n",
        "        normalized_attr = get_norm_attr(file_attr['grad_dict'])\n",
        "        keys = list(normalized_attr.keys())\n",
        "        input_size = len(file_attr['grad_dict'][list(file_attr['grad_dict'].keys())[0]]) # calculate properly once\n",
        "        buffer = 10\n",
        "    #print(get_frame_allignment(file,input_size))\n",
        "    #     with np.printoptions(precision=4, suppress=True):\n",
        "    #         print(normalized_attr[1][:291])\n",
        "        plot_vertical = False\n",
        "        #idx = 0\n",
        "\n",
        "        if(plot_vertical):\n",
        "            fig = plt.figure(figsize = (1,35))\n",
        "            print(get_frame_allignment(file, input_size))\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            sns.heatmap(np.expand_dims(normalized_attr[1][:actual_size], axis = 1),annot = np.expand_dims(allignments, axis = 1), fmt=\"\", cmap='RdBu')\n",
        "            #plt.yticks(rotation=) \n",
        "            #plt.yticks(range(allignments.shape[0]),list(allignments))\n",
        "            plt.show()\n",
        "        else:\n",
        "\n",
        "            fig = plt.figure(figsize = (37,1))\n",
        "            #print(allignments)\n",
        "            allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "            allignments = np.asarray(allignments)            \n",
        "            actual_size = len(allignments)\n",
        "            #actual_size = len(allignments)\n",
        "\n",
        "            print('for',file_attr['output'][keys[idx]])\n",
        "            sns.heatmap(np.expand_dims(np.abs(normalized_attr[keys[idx]][p_start - buffer:p_end + buffer])/np.sum(np.abs(normalized_attr[keys[idx]][p_start - buffer:p_end + buffer])), axis = 0), fmt=\"\", cmap='Greens')\n",
        "            #plt.yticks(rotation=) \n",
        "            modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "            phone_labels = [x[0] for x in groupby(modified_allignments)]\n",
        "            len_list = [len(list(x[1])) for x in groupby(modified_allignments)]\n",
        "            idx_list = [0]\n",
        "            ticks_list = []\n",
        "            for l in len_list:\n",
        "                ticks_list.append(idx_list[-1] + l//2)\n",
        "                idx_list.append(idx_list[-1] + l)\n",
        "\n",
        "            #ticks_list.append((idx_list[-1] + len(modified_allignments))//2)   \n",
        "\n",
        "            plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "\n",
        "            for j in idx_list:\n",
        "                plt.axvline(x=j, color='w', linestyle='-', linewidth=2.5)\n",
        "                plt.axvline(x=j, color='k', linestyle='--', linewidth=2.5)\n",
        "            plt.show()\n",
        "\n",
        "    #break\n",
        "    except:\n",
        "        print('failed for file : {}'.format(file))\n",
        "#         continue\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdSG7nFlRF95"
      },
      "source": [
        "##### Generate **|*Gradient*|** Attribution at word-level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGTH_WKnRF95"
      },
      "outputs": [],
      "source": [
        "#for file in trans_dict[\"I'm going to them.\"]:\n",
        "def grad_word(file, word_idx):\n",
        "    #try:\n",
        "        #file = 'common_voice_en_110121'\n",
        "        #print(file)\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "    with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "        file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "\n",
        "#         print(file_attr['output'].split(' '))\n",
        "    normalized_attr = get_norm_attr(file_attr['grad_dict'])\n",
        "    keys = list(normalized_attr.keys())\n",
        "#         print(keys)\n",
        "    spaces = get_space(file_attr['output'])\n",
        "    indices = [keys.index(x) for x in spaces]\n",
        "    words = get_words(keys,indices, spaces)\n",
        "    input_size = len(file_attr['grad_dict'][list(file_attr['grad_dict'].keys())[0]]) # calculate properly once\n",
        "    buffer = 10\n",
        "    plot_vertical = False\n",
        "    #word_idx = 8\n",
        "#         print(words)\n",
        "#         print(keys)\n",
        "\n",
        "    word_activation = np.sum(np.asarray([np.abs(normalized_attr[idx]) for idx in words[word_idx]] ), axis = 0)\n",
        "\n",
        "    if(plot_vertical):\n",
        "        fig = plt.figure(figsize = (1,35))\n",
        "        print(get_frame_allignment(file, input_size))\n",
        "        allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "        allignments = np.asarray(allignments)            \n",
        "        actual_size = len(allignments)\n",
        "        sns.heatmap(np.expand_dims(normalized_attr[1][:actual_size], axis = 1),annot = np.expand_dims(allignments, axis = 1), fmt=\"\", cmap='RdBu')\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        str_list = []\n",
        "        for x in words[word_idx]:\n",
        "            str_list.append(file_attr['output'][x])\n",
        "\n",
        "\n",
        "        print('Focus word:',''.join(str_list))\n",
        "        fig = plt.figure(figsize = (37,1))\n",
        "        allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "        allignments = np.asarray(allignments)            \n",
        "        actual_size = len(allignments)\n",
        "        #actual_size = len(allignments)\n",
        "\n",
        "        sns.heatmap(np.expand_dims(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer]), axis = 0), fmt=\"\", cmap='Greens')\n",
        "        #plt.yticks(rotation=) [p_start - buffer:p_end + buffer]\n",
        "        modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "        phone_labels = [x[0] for x in groupby(modified_allignments)]\n",
        "        len_list = [len(list(x[1])) for x in groupby(modified_allignments)]\n",
        "        idx_list = [0]\n",
        "        ticks_list = []\n",
        "        for l in len_list:\n",
        "            ticks_list.append(idx_list[-1] + l//2)\n",
        "            idx_list.append(idx_list[-1] + l)\n",
        "\n",
        "\n",
        "        plt.xticks(ticks_list,phone_labels, rotation = 90, fontsize=16)\n",
        "\n",
        "        for j in idx_list:\n",
        "            plt.axvline(x=j, color='w', linestyle='-', linewidth=2.5)\n",
        "            plt.axvline(x=j, color='k', linestyle='--', linewidth=2.5)\n",
        "\n",
        "\n",
        "        plt.show()\n",
        "#         fig2 = plt.figure(figsize = (37,1))\n",
        "#         my_arr = word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer])\n",
        "#         plt.plot(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer]))\n",
        "#         xk = np.arange(len(my_arr))\n",
        "#         #pk = (0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)        \n",
        "#         custm = st.rv_discrete(name='custm', values=(xk, my_arr))\n",
        "#         print(custm.mean(), custm.std())\n",
        "#         #print(my_arr.mean(), my_arr.std())\n",
        "#         #plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "#         plt.xlim(xmin = 0, xmax = len(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer])))\n",
        "        \n",
        "        \n",
        "#         plt.show()\n",
        "\n",
        "#     except:\n",
        "#         print('failed for file : {}'.format(file))\n",
        "        #continue\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elRd5eOxRF95"
      },
      "outputs": [],
      "source": [
        "target_transcript = \"I'm going to them.\" # indian gowmedo\n",
        "target_transcript = 'The burning fire had been extinguished.' #across accents\n",
        "#target_transcript = 'It was the first time she had done that.' #SHE across accents, sheld in usm hi in indian\n",
        "#target_transcript = 'I was scared, but wasted no time in going out and crossing the bridge to the sand pits.'\n",
        "grapheme_idx = 0\n",
        "word_idx = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL8ReQ-URF95"
      },
      "source": [
        "### Visualizing Attributions for all accents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__qKHbdVRF95"
      },
      "source": [
        "#### (A) Grapheme-level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr0LVpnhRF96"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (37,20))\n",
        "for file in trans_dict[target_transcript]:\n",
        "    try:\n",
        "        Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "        display(Audio(wav, rate=Fs))\n",
        "        with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "            file_attr = pickle.load(j)\n",
        "        print(file_attr['output'], file_meta[file]['accent'])\n",
        "        #print(list(file_attr['attr dict'].keys()))\n",
        "        inp_grad_grapheme(file, grapheme_idx)\n",
        "        grad_grapheme(file,grapheme_idx)\n",
        "        \n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw8UId9_RF96"
      },
      "source": [
        "#### (B) Word Level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCE8Z5puRF96"
      },
      "outputs": [],
      "source": [
        "word_idx = 4\n",
        "for file in trans_dict[target_transcript]:\n",
        "    try:\n",
        "        Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "        display(Audio(wav, rate=Fs))\n",
        "        with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "            file_attr = pickle.load(j)\n",
        "        print(file_attr['output'], file_meta[file]['accent'])\n",
        "        #print(list(file_attr['attr dict'].keys()))\n",
        "        inp_grad_word(file, word_idx)\n",
        "        #print(file_meta[file]['accent'])\n",
        "        grad_word(file,word_idx)\n",
        "#     break\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St6-4pxdRF96"
      },
      "outputs": [],
      "source": [
        "syllables = pickle.load(open('syll.pickle','rb'))\n",
        "syllables['THE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsK2V2JuRF96"
      },
      "outputs": [],
      "source": [
        "syllables['PEOPLE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTcYOPCxRF96"
      },
      "outputs": [],
      "source": [
        "def is_correct(s1, s2, idx):\n",
        "        \"\"\"\n",
        "        Computes the Word Error Rate, defined as the edit distance between the\n",
        "        two provided sentences after tokenizing to words.\n",
        "        Arguments:\n",
        "            s1 (string): space-separated sentence\n",
        "            s2 (string): space-separated sentence\n",
        "        \"\"\"\n",
        "\n",
        "        # build mapping of words to integers\n",
        "        b = set(s1.split() + s2.split())\n",
        "        word2char = dict(zip(b, range(len(b))))\n",
        "\n",
        "        # map the words to a char array (Levenshtein packages only accepts\n",
        "        # strings)\n",
        "        w1 = [chr(word2char[w]) for w in s1.split()]\n",
        "        w2 = [chr(word2char[w]) for w in s2.split()]\n",
        "        ops = Lev.editops(''.join(w1), ''.join(w2))\n",
        "        #print(ops)\n",
        "        words_changed = [x[1] for x in ops]\n",
        "        \n",
        "        return not idx in words_changed\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhyuYVloRF96"
      },
      "outputs": [],
      "source": [
        "cond_transcripts = []\n",
        "for t in transcripts:\n",
        "    \n",
        "    order = sorted(transcript_wer[t], key=lambda k: transcript_wer[t][k])\n",
        "    #print(order)\n",
        "    if(order[0]== 'canada' or order[0] == 'us'):\n",
        "        cond_transcripts.append(t)\n",
        "    \n",
        " # do this after LM rescoring ?   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Lg7vWBPRF98"
      },
      "outputs": [],
      "source": [
        "print(len(cond_transcripts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXvOV_3oRF99"
      },
      "outputs": [],
      "source": [
        "print(cond_transcripts[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1l2OnNyRF99"
      },
      "outputs": [],
      "source": [
        "all_words = []\n",
        "valid_punctuation = string.punctuation.replace(\"'\",\"\")\n",
        "for t in transcripts:\n",
        "    t_ = t.strip().upper()\n",
        "    t_ = t_.translate(str.maketrans({a:None for a in valid_punctuation }))\n",
        "    all_words.extend(t_.split())\n",
        "    #print(all_words)\n",
        "    #break\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2NXMdgZRF99"
      },
      "source": [
        "##### Calculate Most Frequent Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c21DM02HRF99"
      },
      "outputs": [],
      "source": [
        "allWordDist = nltk.FreqDist(all_words)\n",
        "record_frequency = allWordDist.most_common(75)\n",
        "most_frequent = [ x[0] for x in record_frequency]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTkE_V3NRF99"
      },
      "outputs": [],
      "source": [
        "print(most_frequent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF2v3QYBRF99"
      },
      "outputs": [],
      "source": [
        "most_frequent = ['THE', 'TO', 'AND', 'A', 'OF', 'WAS', 'I', 'IT', 'HE', 'THAT', 'IN', 'YOU', 'HAD', 'HIS', 'AS', 'BUT', 'WITH', 'BOY', 'IS', 'THEY', 'WERE', 'FOR', 'AT', 'ABOUT', 'BE', 'ON', 'ME', 'THERE', 'FROM', 'MY', 'WE', 'HIM', 'HAVE', 'NOT', 'OUT', 'THIS', 'SOME', 'ALL', 'THOUGHT', 'AN', 'PEOPLE', 'BEEN', 'HER', 'INTO', 'TIME', 'YOUR', 'SO', 'ARE', 'HERE', 'CAN', 'GET', 'THEN', 'WAY', 'SHE', 'ONE', 'WHEN', 'ONLY', \"DON'T\", \"I'M\", 'OTHER', 'UP', 'WHAT', 'SEE', 'COULD', 'LITTLE', 'NO', 'GOING', 'DO', 'WILL', 'IF', 'ITS', 'MORE', 'BY', 'MAN', 'STILL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd7KUNkRRF9-"
      },
      "outputs": [],
      "source": [
        "mf_us = {x:[] for x in most_frequent}\n",
        "mf_canada = {x:[] for x in most_frequent}\n",
        "mf_indian = {x:[] for x in most_frequent}\n",
        "mf_african = {x:[] for x in most_frequent}\n",
        "mf_england = {x:[] for x in most_frequent}\n",
        "mf_scotland = {x:[] for x in most_frequent}\n",
        "mf_australian = {x:[] for x in most_frequent}\n",
        "mf_accents = {'us':mf_us,'canada':mf_canada,'indian':mf_indian,'african':mf_african,'england':mf_england,'scotland':mf_scotland,'australia':mf_australian}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1BYAhP4RF9-"
      },
      "outputs": [],
      "source": [
        "#transcript_freq = {}\n",
        "for t in transcripts:\n",
        "    \n",
        "    t_ = t.strip().upper()\n",
        "    t_ = t_.translate(str.maketrans({a:None for a in valid_punctuation }))\n",
        "    \n",
        "    t_list = t_.split()\n",
        "    true_nz_counts = {x:t_list.count(x) for x in most_frequent if t_list.count(x) > 0}\n",
        "    true_nz_indices = {x:[index for index, value in enumerate(t_list) if value == x] for x in true_nz_counts.keys()}\n",
        "    #print(true_nz_counts)\n",
        "    for file in trans_dict[t]:\n",
        "        try:\n",
        "            acc = {x:0 for x in true_nz_counts.keys()}\n",
        "            with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "                file_attr = pickle.load(j)\n",
        "            op = file_attr['output'].replace('_', '')\n",
        "            accent = file_meta[file]['accent']\n",
        "            \n",
        "            \n",
        "            for w in true_nz_counts.keys():\n",
        "                \n",
        "                for j in true_nz_indices[w]:\n",
        "                #mf_accents[accent][w][0].append(true_nz_counts[w])\n",
        "                    \n",
        "                    mf_accents[accent][w].append(is_correct(t_,op,j))\n",
        "                #print(cond)\n",
        "           \n",
        "                #mf_accents[accent][w][1].append(min(op.split().count(w),true_nz_counts[w]))\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "        #print(mf_accents[accent])\n",
        "    \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQKrmqSORF9-"
      },
      "outputs": [],
      "source": [
        "#print(mf_us)\n",
        "mf_us = {x:[] for x in most_frequent}\n",
        "mf_canada = {x:[] for x in most_frequent}\n",
        "mf_indian = {x:[] for x in most_frequent}\n",
        "mf_african = {x:[] for x in most_frequent}\n",
        "mf_england = {x:[] for x in most_frequent}\n",
        "mf_scotland = {x:[] for x in most_frequent}\n",
        "mf_australian = {x:[] for x in most_frequent}\n",
        "avg_stats =  {'us':mf_us,'canada':mf_canada,'indian':mf_indian,'african':mf_african,'england':mf_england,'scotland':mf_scotland,'australia':mf_australian}\n",
        "#print(avg_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWY24rb4RF9-"
      },
      "outputs": [],
      "source": [
        "for a in mf_accents.keys():\n",
        "    print(a)\n",
        "    #a = 'indian'\n",
        "    for w in mf_accents[a].keys():\n",
        "        \n",
        "        avg_stats[a][w].append(sum(mf_accents[a][w])/len(mf_accents[a][w]))\n",
        "        \n",
        "        #print(w,np.asarray(mf_accents[a][w]).mean(),np.asarray(mf_accents[a][w]).std())\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23U8bzXVRF9-"
      },
      "source": [
        "##### Accuracy of correctly predicting most frequent words across accents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoMqceXQRF9-"
      },
      "outputs": [],
      "source": [
        "for a in avg_stats.keys():\n",
        "    temp = []\n",
        "    for k in avg_stats[a].keys():\n",
        "        temp.append(avg_stats[a][k][0])\n",
        "    print(a, np.asarray(temp).mean(), np.asarray(temp).std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYgEsSGjRF9_"
      },
      "outputs": [],
      "source": [
        "us = [0.7803950509449439, 0.121667382968697]\n",
        "canada =[0.8572825991328428, 0.10528083986888306]\n",
        "indian =[0.513035145387385, 0.18122269227720902]\n",
        "african =[0.7522708227207352, 0.1365991362807828]\n",
        "england =[0.6919775766172566, 0.16313311778908576]\n",
        "scotland =[0.6535836230311115, 0.1547649386757295]\n",
        "australia =[0.7459351700052215, 0.14893722495703424]\n",
        "acc = {'us':us,'indian':indian,'canada':canada,'african':african,'england':england,'scotland':scotland,'australia':australia}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHPwfv4CRF9_"
      },
      "outputs": [],
      "source": [
        "objects = ['us', 'indian', 'african', 'canada', 'england', 'australia', 'scotland']\n",
        "y_pos = np.arange(len(objects))\n",
        "#fig = plt.figure(figsize = (15,10))\n",
        "# def create_plots(layer, name):\n",
        "fig = plt.figure(figsize = (10,5))\n",
        "y_pos = np.arange(len(objects))\n",
        "y = [100*acc[x][0] for x in objects ]\n",
        "err = [100*acc[x][1]  for  x in objects]\n",
        "#plt.plot(y_pos, y,'-o', alpha=0.7,)\n",
        "#plt.figure()\n",
        "plt.bar(y_pos, y, yerr= err,align='center', capsize=7, edgecolor='k')\n",
        "plt.xticks(y_pos, objects, fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "# plt.errorbar(y_pos, y, yerr=err,fmt='-o',capsize=5 )\n",
        "# plt.xticks(y_pos, objects)\n",
        "#plt.ylim(ymin = 0)obj\n",
        "#plt.axhline(14.28, linewidth=1, color='k')\n",
        "plt.ylabel('Accuracy %',color='k',fontsize=18)\n",
        "plt.xlabel('Accents',color='k',fontsize=18)\n",
        "#plt.title('MF words classificant trends')\n",
        "#plt.legend(frameon=False)\n",
        "plt.savefig('MF-words.pdf',bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uEz4jv9RF9_"
      },
      "source": [
        "##### Helper Function for alligning words with frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcAj1khiRF9_"
      },
      "outputs": [],
      "source": [
        "def get_word_allignment(file, input_size):\n",
        "    alligned = []\n",
        "    spec_stride = 0.01\n",
        "    window_size = 0.02\n",
        "    times = file_meta[file]['end_times']\n",
        "    json_path = 'my_data/align_common/{}.json'.format(file)\n",
        "    with open(json_path,'r') as j:\n",
        "        gentle = json.load(j)\n",
        "    word_ends = []\n",
        "    word_ends.append(('start',times[0]))\n",
        "    for g in range(len(gentle['words'])):\n",
        "        word_ends.append((gentle['words'][g]['word'], gentle['words'][g]['end']))\n",
        "    word_ends.append(('end',times[-1]))\n",
        "    \n",
        "    #last_idx = 0\n",
        "    for i in range(input_size):\n",
        "        frame_idx = i\n",
        "        window_start = frame_idx*spec_stride\n",
        "        window_mid = window_start + (window_size/2)\n",
        "        alligned_word = 'na'\n",
        "        for j in range(len(word_ends)):\n",
        "            if (window_mid < word_ends[j][1]):\n",
        "                alligned_word = word_ends[j][0]\n",
        "                break\n",
        "        #assert alligned_phone != 'na', \"Failed to fetch allignment\"\n",
        "        if(alligned_word != 'na'):\n",
        "            alligned.append(alligned_word)\n",
        "            #last_idx = i\n",
        "    pause_start = 0\n",
        "    pause_end = len(alligned)\n",
        "    for i in range(len(alligned)):\n",
        "        if(alligned[i] != 'start'):\n",
        "            break\n",
        "        pause_start = i\n",
        "    \n",
        "    for i in range(len(alligned)-1,-1,-1):\n",
        "        if(alligned[i] != 'end'):\n",
        "            break\n",
        "        pause_end = i\n",
        "        \n",
        "    #print(last_idx)\n",
        "    \n",
        "    return alligned, pause_start+1, pause_end,\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ2qU00yRF9_"
      },
      "outputs": [],
      "source": [
        "wrd = get_word_allignment('common_voice_en_540956', 100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KR7XEv_RF-A"
      },
      "source": [
        "### Visualizing attribution of a particular word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdBEGLilRF-A"
      },
      "outputs": [],
      "source": [
        "def grad_clubbed_word(file, word_idx, disable_prints = False):\n",
        "    \n",
        "    #try:\n",
        "        #file = 'common_voice_en_110121'\n",
        "        #print(file)\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "    with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "        file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "\n",
        "#         print(file_attr['output'].split(' '))\n",
        "    normalized_attr = get_norm_attr(file_attr['grad_dict'])\n",
        "    keys = list(normalized_attr.keys())\n",
        "#         print(keys)\n",
        "    spaces = get_space(file_attr['output'])\n",
        "    indices = [keys.index(x) for x in spaces]\n",
        "    words = get_words(keys,indices, spaces)\n",
        "    input_size = len(file_attr['grad_dict'][list(file_attr['grad_dict'].keys())[0]]) # calculate properly once\n",
        "    buffer = 10\n",
        "    plot_vertical = False\n",
        "    #word_idx = 8\n",
        "#         print(words)\n",
        "#         print(keys)\n",
        "\n",
        "    word_activation = np.sum(np.asarray([np.abs(normalized_attr[idx]) for idx in words[word_idx]] ), axis = 0)\n",
        "    \n",
        "\n",
        "    if(plot_vertical):\n",
        "        fig = plt.figure(figsize = (1,35))\n",
        "        print(get_frame_allignment(file, input_size))\n",
        "        allignments, p_start, p_end = get_word_allignment(file, input_size)\n",
        "        allignments = np.asarray(allignments)            \n",
        "        actual_size = len(allignments)\n",
        "        sns.heatmap(np.expand_dims(normalized_attr[1][:actual_size], axis = 1),annot = np.expand_dims(allignments, axis = 1), fmt=\"\", cmap='RdBu')\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        str_list = []\n",
        "        for x in words[word_idx]:\n",
        "            str_list.append(file_attr['output'][x])\n",
        "\n",
        "\n",
        "        \n",
        "        allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "        wrd_allignments,w_start,w_end = get_word_allignment(file, input_size)\n",
        "        wrd_allignments = np.asarray(wrd_allignments)\n",
        "        allignments = np.asarray(allignments)            \n",
        "        actual_size = len(allignments)\n",
        "        #actual_size = len(allignments)\n",
        "        \n",
        "        #plt.yticks(rotation=) [p_start - buffer:p_end + buffer]\n",
        "        modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "        assert len(wrd_allignments) == len(allignments), \"dimensions don't match\"\n",
        "        \n",
        "        modified_wrd_allignments = wrd_allignments[w_start - buffer:w_end + buffer]\n",
        "        #assert len(modified_wrd_allignments) == len(modified_allignments), \"dimensions don't match\"\n",
        "        #wrds = [list(x[0]) for x in groupby(modified_wrd_allignments)]\n",
        "        wrd_labels = [list(x[1]) for x in groupby(modified_wrd_allignments)]\n",
        "        #print(wrd_labels)\n",
        "        wrd_indices = [0]\n",
        "        for j in wrd_labels:\n",
        "            wrd_indices.append(wrd_indices[-1] + len(j))\n",
        "        #print(wrd_indices)\n",
        "        my_arr = word_activation[w_start - buffer:w_end + buffer]/np.sum(word_activation[w_start - buffer:w_end + buffer])\n",
        "        wrd_combined_wonorm = []\n",
        "        wrd_combined = []\n",
        "        for m in range(len(wrd_labels)):\n",
        "            wrd_combined_wonorm.append(np.sum(my_arr[wrd_indices[m]:wrd_indices[m+1]]))\n",
        "            wrd_combined.append(np.sum(my_arr[wrd_indices[m]:wrd_indices[m+1]])/len(wrd_labels[m]))\n",
        "        wrd_combined = np.asarray(wrd_combined)\n",
        "        \n",
        "        wrd_combined = wrd_combined/np.sum(wrd_combined)\n",
        "        \n",
        "        #print(np.asarray(wrd_combined).sum())\n",
        "        if(not disable_prints):\n",
        "            print(''.join(str_list))\n",
        "            fig = plt.figure(figsize = (37,1))\n",
        "            sns.heatmap(np.expand_dims(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer]), axis = 0), fmt=\"\", cmap='Greens')\n",
        "            phone_labels = [x[0] for x in groupby(modified_allignments)]\n",
        "            len_list = [len(list(x[1])) for x in groupby(modified_allignments)]\n",
        "            idx_list = [0]\n",
        "            ticks_list = []\n",
        "            for l in len_list:\n",
        "                ticks_list.append(idx_list[-1] + l//2)\n",
        "                idx_list.append(idx_list[-1] + l)\n",
        "\n",
        "\n",
        "            plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "\n",
        "            for j in idx_list:\n",
        "                plt.axvline(x=j, color='w', linestyle='-', linewidth=2.5)\n",
        "                plt.axvline(x=j, color='k', linestyle='--', linewidth=2.5)\n",
        "\n",
        "\n",
        "            plt.show()\n",
        "            print(wrd_combined_wonorm)\n",
        "            print(wrd_combined)  \n",
        "            fig2 = plt.figure(figsize = (37,1))\n",
        "            #my_arr = word_activation[w_start - buffer:w_end + buffer]/np.sum(word_activation[w_start - buffer:w_end + buffer])\n",
        "            plt.plot(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer]))\n",
        "            xk = np.arange(len(my_arr))\n",
        "            #pk = (0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)        \n",
        "            custm = st.rv_discrete(name='custm', values=(xk, my_arr))\n",
        "            print(custm.mean(), custm.std())\n",
        "              \n",
        "            #print(my_arr.mean(), my_arr.std())\n",
        "            #plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "            plt.xlim(xmin = 0, xmax = len(word_activation[p_start - buffer:p_end + buffer]/np.sum(word_activation[p_start - buffer:p_end + buffer])))\n",
        "\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            fig3 = plt.figure(figsize = (37,1))\n",
        "            my_arr = wrd_combined\n",
        "            plt.plot(my_arr)\n",
        "            xk = np.arange(len(my_arr))\n",
        "            #pk = (0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)        \n",
        "            custm = st.rv_discrete(name='custm', values=(xk, my_arr))\n",
        "            print(custm.mean(), custm.std())\n",
        "            #print(my_arr.mean(), my_arr.std())\n",
        "            #plt.xticks(ticks_list,phone_labels, rotation = 90)\n",
        "            plt.xlim(xmin = 0, xmax = len(my_arr))\n",
        "\n",
        "\n",
        "            plt.show()\n",
        "        #else:\n",
        "        return wrd_combined, wrd_combined_wonorm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WlP5ZUxRF-A"
      },
      "source": [
        "##### Visualizing normalized attributions at granularity of frames and words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P-BBkD2RF-A"
      },
      "outputs": [],
      "source": [
        "#target_transcript = 'I was scared, but wasted no time in going out and crossing the bridge to the sand pits.'\n",
        "\n",
        "for file in trans_dict[target_transcript]:\n",
        "    Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "    display(Audio(wav, rate=Fs))\n",
        "    with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "        file_attr = pickle.load(j)\n",
        "    print(file_attr['output'], file_meta[file]['accent'])\n",
        "    print(list(file_attr['attr dict'].keys()))\n",
        "    #inp_grad_grapheme(file, grapheme_idx)\n",
        "    print(file)\n",
        "    distr, distr_wo = grad_clubbed_word(file, 2*idx, disable_prints=False)\n",
        "                    #print(distr)\n",
        "    max_idx = np.argmax(np.asarray(distr))\n",
        "    max_idx_wo = np.argmax(np.asarray(distr_wo))\n",
        "    custm = st.rv_discrete(name='custm', values=(np.arange(len(distr)), distr))\n",
        "    spread = custm.expect(lambda x : (x- custm.mean())**2)\n",
        "    print(max_idx,spread**0.5)\n",
        "          \n",
        "    #break\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOLfAZskRF-A"
      },
      "source": [
        "#### Analysis of attributions summed at word level (from transcription)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocufOJ7YRF-A"
      },
      "outputs": [],
      "source": [
        "mf_us = {x:([],[],[]) for x in most_frequent}\n",
        "mf_canada = {x:([],[],[]) for x in most_frequent}\n",
        "mf_indian = {x:([],[],[]) for x in most_frequent}\n",
        "mf_african = {x:([],[],[]) for x in most_frequent}\n",
        "mf_england = {x:([],[],[]) for x in most_frequent}\n",
        "mf_scotland = {x:([],[],[]) for x in most_frequent}\n",
        "mf_australian = {x:([],[],[]) for x in most_frequent}\n",
        "max_accents = {'us':mf_us,'canada':mf_canada,'indian':mf_indian,'african':mf_african,'england':mf_england,'scotland':mf_scotland,'australia':mf_australian}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm4D0JSBRF-B"
      },
      "outputs": [],
      "source": [
        "\n",
        "for t in transcripts:\n",
        "    \n",
        "    t_ = t.strip().upper()\n",
        "    t_ = t_.translate(str.maketrans({a:None for a in valid_punctuation }))\n",
        "    #print(t_)\n",
        "    t_list = t_.split()\n",
        "    true_nz_counts = {x:t_list.count(x) for x in most_frequent if t_list.count(x) > 0}\n",
        "    true_nz_indices = {x:[index for index, value in enumerate(t_list) if value == x] for x in true_nz_counts.keys()}\n",
        "    \n",
        "    for file in trans_dict[t]:\n",
        "        \n",
        "        try:   \n",
        "            with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "                file_attr = pickle.load(j)\n",
        "            op = file_attr['output'].replace('_', '')\n",
        "            op_list = op.split()\n",
        "            accent = file_meta[file]['accent']\n",
        "\n",
        "            a_indices = {x:[index for index, value in enumerate(op_list) if value == x] for x in true_nz_counts.keys()}\n",
        "        \n",
        "            for w in true_nz_counts.keys():\n",
        "                for idx in a_indices[w]:\n",
        "                    # compute condition for correctness\n",
        "                    distr, distr_wo = grad_clubbed_word(file, 2*idx, disable_prints=True)\n",
        "                    #print(distr)\n",
        "                    max_idx = np.argmax(np.asarray(distr))\n",
        "                    max_idx_wo = np.argmax(np.asarray(distr_wo))\n",
        "                    \n",
        "            #print(custm.mean(), custm.std())\n",
        "                    if(is_correct(op,t_,idx)):\n",
        "                        custm = st.rv_discrete(name='custm', values=(np.arange(len(distr)), distr))\n",
        "                        spread = custm.expect(lambda x : (x - max_idx)**2)\n",
        "                        #print(spread)\n",
        "                        max_accents[accent][w][2].append(spread**0.5)\n",
        "                        \n",
        "                        idx2 = true_nz_indices[w][a_indices[w].index(idx)]\n",
        "                        max_accents[accent][w][0].append(max_idx == idx2 + 1)\n",
        "                        max_accents[accent][w][1].append(max_idx_wo == idx2 + 1)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "            \n",
        "        #print(mf_accents[accent])\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p9kv2rsRF-B"
      },
      "source": [
        "##### Accuracy of how often the word alligned from meta data has the highest cumulative attribtuion for words from transcription (given that word is transcribed correctly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvF7sx2GRF-B"
      },
      "outputs": [],
      "source": [
        "for a in max_accents.keys():\n",
        "    print(a)\n",
        "    acc = ([],[],[])\n",
        "    #a = 'indian'\n",
        "    for w in mf_accents[a].keys():\n",
        "        acc[0].append(sum(max_accents[a][w][0])/len(max_accents[a][w][0]))\n",
        "        acc[1].append(sum(max_accents[a][w][1])/len(max_accents[a][w][1]))\n",
        "        #acc[2].append(np.asarray(max_accents[a][w][2]).mean())\n",
        "    print(np.asarray(acc[0]).mean(),np.asarray(acc[1]).mean(),np.asarray(acc[2]).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOPUpZkBRF-B"
      },
      "outputs": [],
      "source": [
        "# us\n",
        "# 0.822280626362392 0.7107428299869577\n",
        "# canada\n",
        "# 0.8579726753622985 0.7690201257461524\n",
        "# indian\n",
        "# 0.7958703395891465 0.6934186392183957\n",
        "# african\n",
        "# 0.8308889379878893 0.7204420312446458\n",
        "# england\n",
        "# 0.7781214935118137 0.7200572594990948\n",
        "# scotland\n",
        "# 0.8124665953005906 0.7094160821071285\n",
        "# australia\n",
        "# 0.7892047076340786 0.7292303868344401"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi89lTs5RF-D"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(predictions, targets,N):\n",
        "    \"\"\"\n",
        "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
        "    and predictions. \n",
        "    Input: predictions (N, k) ndarray\n",
        "           targets (N, k) ndarray        \n",
        "    Returns: scalar\n",
        "    \"\"\"\n",
        "    #predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
        "    #N = predictions.shape[0]\n",
        "    ce = -np.sum(targets*np.log(predictions+1e-9))/N\n",
        "    return ce\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZOm-uXrRF-D"
      },
      "source": [
        "### EMD Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHSoz4URF-E"
      },
      "source": [
        "##### EMD & entropy wrt baselines at word level. Wd1 and e1 correspond to emd and entropy between the segment of at attribution of frame corresponding to the word and a uniformly distributed baseline for the duration of the word respectively. Wd2 and e2 correspond to emd and entropy between the attribution of the entire transcription and a uniformly distributed baseline for the duration of the word and zero every where else respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THzZA9X-RF-E"
      },
      "outputs": [],
      "source": [
        "def grad_word_dist(file, word_idx, actual_idx, taper = False):\n",
        "    \n",
        "    #try:\n",
        "        #file = 'common_voice_en_110121'\n",
        "        #print(file)\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "    with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "        file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "\n",
        "#         print(file_attr['output'].split(' '))\n",
        "    normalized_attr = get_norm_attr(file_attr['grad_dict'])\n",
        "    keys = list(normalized_attr.keys())\n",
        "#         print(keys)\n",
        "    spaces = get_space(file_attr['output'])\n",
        "    indices = [keys.index(x) for x in spaces]\n",
        "    words = get_words(keys,indices, spaces)\n",
        "    input_size = len(file_attr['grad_dict'][list(file_attr['grad_dict'].keys())[0]]) # calculate properly once\n",
        "    buffer = 10\n",
        "    plot_vertical = False\n",
        "    #word_idx = 8\n",
        "#         print(words)\n",
        "#         print(keys)\n",
        "\n",
        "    word_activation = np.sum(np.asarray([np.abs(normalized_attr[idx]) for idx in words[word_idx]] ), axis = 0)\n",
        "    \n",
        "\n",
        "\n",
        "    str_list = []\n",
        "    for x in words[word_idx]:\n",
        "        str_list.append(file_attr['output'][x])\n",
        "\n",
        "\n",
        "    #print(''.join(str_list))\n",
        "    allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "    wrd_allignments,w_start,w_end = get_word_allignment(file, input_size)\n",
        "    wrd_allignments = np.asarray(wrd_allignments)\n",
        "    allignments = np.asarray(allignments)            \n",
        "    actual_size = len(allignments)\n",
        "    \n",
        "    modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "    assert len(wrd_allignments) == len(allignments), \"dimensions don't match\"\n",
        "    modified_allignments = allignments[w_start - buffer:w_end + buffer]\n",
        "    modified_wrd_allignments = wrd_allignments[w_start - buffer:w_end + buffer]\n",
        "    \n",
        "    wrd_labels = [list(x[1]) for x in groupby(modified_wrd_allignments)]\n",
        "#     print(wrd_labels)\n",
        "    wrd_indices = [0]\n",
        "    for j in wrd_labels:\n",
        "        wrd_indices.append(wrd_indices[-1] + len(j))\n",
        "#     print(wrd_indices)\n",
        "    my_arr = word_activation[w_start - buffer:w_end + buffer]/np.sum(word_activation[w_start - buffer:w_end + buffer])\n",
        "    m = actual_idx + 1\n",
        "#     print(m)\n",
        "    \n",
        "    assert len(my_arr) == len(modified_wrd_allignments), 'assumption failed'\n",
        "    word_frame = my_arr[wrd_indices[m]:wrd_indices[m+1]]\n",
        "    word_frame_norm = word_frame/np.sum(word_frame)\n",
        "    baseline_frame_ = np.ones(len(word_frame))/len(word_frame)\n",
        "    baseline_frame = np.array(signal.tukey(int(2*len(word_frame))))\n",
        "    if(not taper):\n",
        "        baseline_frame = baseline_frame_\n",
        "#     print('here')\n",
        "#     print(len(baseline_frame))\n",
        "#     print(len(baseline_wind[wrd_indices[m]:wrd_indices[m+1]]))\n",
        "\n",
        "    baseline_frame = baseline_frame / sum(baseline_frame)\n",
        "#     print(len(baseline_frame))\n",
        "#     print(wrd_indices[m+1] - wrd_indices[m])\n",
        "    count = len(set(modified_allignments[wrd_indices[m]:wrd_indices[m+1]]))#huersitic\n",
        "    (wd1,e1) = 100*wd(word_frame_norm,baseline_frame_)/count, cross_entropy(word_frame_norm,baseline_frame_,count)\n",
        "    baseline_wind = np.zeros(len(my_arr))\n",
        "    if(not taper):\n",
        "        baseline_wind[wrd_indices[m] :wrd_indices[m+1] ] = baseline_frame\n",
        "    else : \n",
        "        if(wrd_indices[m] - len(word_frame)//2 >= 0 and wrd_indices[m+1] + len(word_frame) - len(word_frame)//2 < len(my_arr)):\n",
        "            baseline_wind[wrd_indices[m] - len(word_frame)//2 :wrd_indices[m+1] + len(word_frame) - len(word_frame)//2 ] = baseline_frame\n",
        "        elif(wrd_indices[m] - len(word_frame)//2 < 0):\n",
        "            baseline_wind[0:wrd_indices[m+1] + len(word_frame) - len(word_frame)//2 ] = baseline_frame[-wrd_indices[m] + len(word_frame)//2]\n",
        "        else:\n",
        "            dist = len(my_arr) - (wrd_indices[m+1] + len(word_frame) - len(word_frame)//2)\n",
        "            baseline_wind[wrd_indices[m] - len(word_frame)//2 : len(my_arr) ] = baseline_frame[:len(word_frame) - dist]\n",
        "            \n",
        "            \n",
        "    #my_arr = my_arr/sum(my_arr)\n",
        "#     plt.plot(my_arr)\n",
        "# #     print(round(sum(my_arr),2))\n",
        "#     plt.plot(baseline_wind)\n",
        "# #     print(round(sum(baseline_wind),2))\n",
        "#     plt.show()\n",
        "    #print(wrd_indices)\n",
        "    \n",
        "    #\n",
        "    \n",
        "#     (wd2, e2) = 100*wd(my_arr,baseline_wind)/len(my_arr), cross_entropy(my_arr,baseline_wind,len(my_arr))\n",
        "    bins = np.arange(len(my_arr))\n",
        "    euc_dist = ed(bins.reshape(-1,1), bins.reshape(-1,1))\n",
        "    (wd2, e2) = 100*wd(my_arr,baseline_wind), emd(my_arr.astype(np.float64),baseline_wind.astype(np.float64), euc_dist.astype(np.float64))\n",
        "    return wd1, e1, wd2,e2\n",
        "    \n",
        "    \n",
        "    \n",
        "#     wrd_combined_wonorm = []\n",
        "#     wrd_combined = []\n",
        "#     for m in range(len(wrd_labels)):\n",
        "#         wrd_combined_wonorm.append(np.sum(my_arr[wrd_indices[m]:wrd_indices[m+1]]))\n",
        "#         wrd_combined.append(np.sum(my_arr[wrd_indices[m]:wrd_indices[m+1]])/len(wrd_labels[m]))\n",
        "#     wrd_combined = np.asarray(wrd_combined)\n",
        "\n",
        "#     wrd_combined = wrd_combined/np.sum(wrd_combined)\n",
        "#     print(''.join(str_list))\n",
        "\n",
        "    #return wrd_combined, wrd_combined_wonorm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m_4bQd_RF-E"
      },
      "source": [
        "##### EMD & entropy wrt baselines at syllable level. (wd1, e1), (wd2, e2) represent the same things as above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYG4hIXxRF-F"
      },
      "outputs": [],
      "source": [
        "def grad_syll_dist(file, word_idx, actual_idx, syll_num, taper = False):\n",
        "    \n",
        "    #try:\n",
        "        #file = 'common_voice_en_110121'\n",
        "        #print(file)\n",
        "#         Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#         display(Audio(wav, rate=Fs))\n",
        "    with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "        file_attr = pickle.load(j)\n",
        "#         print(file_attr['output'], file_meta[file]['accent'])\n",
        "\n",
        "#     print(file_attr['output'])\n",
        "    normalized_attr = get_norm_attr(file_attr['grad_dict'])\n",
        "    keys = list(normalized_attr.keys())\n",
        "    #print(keys)\n",
        "    sent = file_attr['output'].replace('_','').lower()\n",
        "    chunks = {}\n",
        "    for chunk in sent.split():\n",
        "        chunks[chunk.upper()] = hyphenate_word(chunk)\n",
        "        #print(syllables[chunk.upper()])\n",
        "    #chunks = [x.upper() for x in chunks]\n",
        "    #print(chunks)\n",
        "    mod_sent = ' '.join(chunks)\n",
        "    spaces = get_space(file_attr['output']) \n",
        "    #print(spaces)\n",
        "    indices = [keys.index(x) for x in spaces]\n",
        "    #print(indices)\n",
        "    words = get_words(keys,indices, spaces)\n",
        "    #print(words)\n",
        "    w_new = []\n",
        "    mult_syll = False\n",
        "    for w in words:\n",
        "        if(len(w) ==1 and w[0] in spaces):\n",
        "            w_new.append(w)\n",
        "            continue\n",
        "        #print(w)\n",
        "        can = ''.join([file_attr['output'][i] for i in w])\n",
        "        if(len(chunks[can]) == 1): w_new.append(w)\n",
        "        else:\n",
        "#             mult_syll = True\n",
        "            Inputt = iter(w)\n",
        "            length_to_split = [len(i) for i in chunks[can]]\n",
        "            Output = [list(islice(Inputt, elem)) for elem in length_to_split]\n",
        "            w_new.extend(Output)\n",
        "    #print(w_new)\n",
        "#     print(mult_syll)   \n",
        "    input_size = len(file_attr['grad_dict'][list(file_attr['grad_dict'].keys())[0]]) # calculate properly once\n",
        "    buffer = 10\n",
        "    plot_vertical = False\n",
        "    #word_idx = 8\n",
        "#         print(words)\n",
        "#         print(keys)\n",
        "    syll_idx = word_idx + syll_num\n",
        "    #print(w_new[syll_idx])\n",
        "    word_activation = np.sum(np.asarray([np.abs(normalized_attr[idx]) for idx in w_new[syll_idx]] ), axis = 0)\n",
        "    \n",
        "\n",
        "\n",
        "    str_list = []\n",
        "\n",
        "    for x in w_new[syll_idx]:\n",
        "        str_list.append(file_attr['output'][x])\n",
        "\n",
        "\n",
        "#     print(''.join(str_list))\n",
        "    allignments, p_start, p_end = get_frame_allignment(file, input_size)\n",
        "    wrd_allignments,w_start,w_end = get_word_allignment(file, input_size)\n",
        "    #print('here',allignments)\n",
        "    wrd_allignments = np.asarray(wrd_allignments)\n",
        "    allignments = np.asarray(allignments)            \n",
        "    actual_size = len(allignments)\n",
        "    \n",
        "    modified_allignments = allignments[p_start - buffer:p_end + buffer]\n",
        "    assert len(wrd_allignments) == len(allignments), \"dimensions don't match\"\n",
        "    modified_allignments = allignments[w_start - buffer:w_end + buffer]\n",
        "    modified_wrd_allignments = wrd_allignments[w_start - buffer:w_end + buffer]\n",
        "#     print(modified_allignments)\n",
        "#     print(modified_wrd_allignments)\n",
        "    \n",
        "    \n",
        "    wrd_labels = [list(x[1]) for x in groupby(modified_wrd_allignments)]\n",
        "#     print(wrd_labels)\n",
        "    wrd_indices = [0]\n",
        "    for j in wrd_labels:\n",
        "        wrd_indices.append(wrd_indices[-1] + len(j))\n",
        "#     print(wrd_indices)\n",
        "\n",
        "    my_arr = word_activation[w_start - buffer:w_end + buffer]/np.sum(word_activation[w_start - buffer:w_end + buffer])\n",
        "    m = actual_idx + 1\n",
        "#     print(m)\n",
        "#     print(modified_allignments[wrd_indices[m] :wrd_indices[m+1]])\n",
        "    \n",
        "    #target_word = wrd_labels[a]\n",
        "    #print()\n",
        "    #print(chunks[])\n",
        "    items = modified_allignments[wrd_indices[m] :wrd_indices[m+1]]\n",
        "    my_pron = list(OrderedDict.fromkeys(items))\n",
        "    my_pron = ' '.join(my_pron).upper()\n",
        "#     print(my_pron)\n",
        "    my_syll = syllables[wrd_labels[m][0]]\n",
        "    if(len(my_syll) > 1): mult_syll = True\n",
        "    flag = True\n",
        "    item_labels = [list(x[1]) for x in groupby(items)]\n",
        "    item_lens = [len(x) for x in item_labels]\n",
        "    for i in range(len(syllables[wrd_labels[m][0]])):\n",
        "        if (my_syll[i]['pron'] == my_pron):\n",
        "            flag = False\n",
        "            assert len(my_syll[i]['syll']) == len(hyphenate_word(wrd_labels[m][0])), 'syll-hyph failed'\n",
        "            phn_splits = []\n",
        "            for j in my_syll[i]['syll']:\n",
        "                j = [k for k in j if len(k)!=0 ]\n",
        "#                 print(j)\n",
        "                phn_splits.append(len(j))\n",
        "    Inputt = iter(item_lens)\n",
        "    length_to_split = phn_splits\n",
        "    Output = [list(islice(Inputt, elem)) for elem in length_to_split]\n",
        "    syll_indices = [0]\n",
        "    syll_indices.extend([sum(j) for j in Output])\n",
        "#     print(syll_indices)\n",
        "#     print(wrd_indices[m], wrd_indices[m+1])\n",
        "    assert not flag, 'no syllables'\n",
        "    \n",
        "#     print(Output)\n",
        "#     print(item_lens)    \n",
        "    assert len(my_arr) == len(modified_wrd_allignments), 'assumption failed'\n",
        "    word_frame = my_arr[wrd_indices[m]:wrd_indices[m+1]]\n",
        "    word_frame_norm = word_frame/np.sum(word_frame)\n",
        "    baseline_frame_ = np.ones(len(word_frame))/len(word_frame)\n",
        "    baseline_frame = np.array(signal.tukey(int(2*len(word_frame))))\n",
        "    if(not taper):\n",
        "        baseline_frame = baseline_frame_\n",
        "#     print('here')\n",
        "#     print(len(baseline_frame))\n",
        "#     print(len(baseline_wind[wrd_indices[m]:wrd_indices[m+1]]))\n",
        "\n",
        "    baseline_frame = baseline_frame / sum(baseline_frame)\n",
        "#     print(len(baseline_frame))\n",
        "#     print(wrd_indices[m+1] - wrd_indices[m])\n",
        "    count = len(set(modified_allignments[wrd_indices[m]:wrd_indices[m+1]]))#huersitic\n",
        "    (wd1,e1) = 100*wd(word_frame_norm,baseline_frame_)/count, cross_entropy(word_frame_norm,baseline_frame_,count)\n",
        "    baseline_wind = np.zeros(len(my_arr))\n",
        "    if(not taper):\n",
        "        if( not mult_syll):\n",
        "            baseline_wind[wrd_indices[m] :wrd_indices[m+1] ] = baseline_frame\n",
        "        else:\n",
        "            #print()\n",
        "            baseline_syll = np.ones(syll_indices[syll_num +1 ] - syll_indices[syll_num])\n",
        "            baseline_syll = baseline_syll/len(baseline_syll)\n",
        "            baseline_wind[wrd_indices[m] + syll_indices[syll_num] : wrd_indices[m] + syll_indices[syll_num + 1] ] = baseline_syll\n",
        "            \n",
        "            \n",
        "    else : \n",
        "        if(wrd_indices[m] - len(word_frame)//2 >= 0 and wrd_indices[m+1] + len(word_frame) - len(word_frame)//2 < len(my_arr)):\n",
        "            baseline_wind[wrd_indices[m] - len(word_frame)//2 :wrd_indices[m+1] + len(word_frame) - len(word_frame)//2 ] = baseline_frame\n",
        "        elif(wrd_indices[m] - len(word_frame)//2 < 0):\n",
        "            baseline_wind[0:wrd_indices[m+1] + len(word_frame) - len(word_frame)//2 ] = baseline_frame[-wrd_indices[m] + len(word_frame)//2]\n",
        "        else:\n",
        "            dist = len(my_arr) - (wrd_indices[m+1] + len(word_frame) - len(word_frame)//2)\n",
        "            baseline_wind[wrd_indices[m] - len(word_frame)//2 : len(my_arr) ] = baseline_frame[:len(word_frame) - dist]\n",
        "            \n",
        "            \n",
        "    #my_arr = my_arr/sum(my_arr)\n",
        "#     plt.plot(my_arr)\n",
        "# #     print(round(sum(my_arr),2))\n",
        "#     plt.plot(baseline_wind)\n",
        "# #     print(round(sum(baseline_wind),2))\n",
        "#     plt.show()\n",
        "    #print(wrd_indices)\n",
        "    \n",
        "    #\n",
        "    \n",
        "#     (wd2, e2) = 100*wd(my_arr,baseline_wind)/len(my_arr), cross_entropy(my_arr,baseline_wind,len(my_arr))\n",
        "    bins = np.arange(len(my_arr))\n",
        "    euc_dist = ed(bins.reshape(-1,1), bins.reshape(-1,1))\n",
        "    (wd2, e2) = 100*wd(my_arr,baseline_wind), emd(my_arr.astype(np.float64),baseline_wind.astype(np.float64), euc_dist.astype(np.float64))\n",
        "    return wd1, e1, wd2,e2\n",
        "    \n",
        "    \n",
        "    \n",
        "#     wrd_combined_wonorm = []\n",
        "#     wrd_combined = []\n",
        "#     for m in range(len(wrd_labels)):\n",
        "#         wrd_combined_wonorm.append(np.sum(my_arr[wrd_indices[m]:wrd_indices[m+1]]))\n",
        "#         wrd_combined.append(np.sum(my_arr[wrd_indices[m]:wrd_indices[m+1]])/len(wrd_labels[m]))\n",
        "#     wrd_combined = np.asarray(wrd_combined)\n",
        "\n",
        "#     wrd_combined = wrd_combined/np.sum(wrd_combined)\n",
        "#     print(''.join(str_list))\n",
        "\n",
        "    #return wrd_combined, wrd_combined_wonorm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx8uHX7QRF-F"
      },
      "outputs": [],
      "source": [
        "grad_syll_dist('common_voice_en_179645',2,1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8QqNPEeRF-F"
      },
      "outputs": [],
      "source": [
        "\n",
        "mf_us = {x:([],[],[],[]) for x in most_frequent}\n",
        "mf_canada = {x:([],[],[],[]) for x in most_frequent}\n",
        "mf_indian = {x:([],[],[],[]) for x in most_frequent}\n",
        "mf_african = {x:([],[],[],[]) for x in most_frequent}\n",
        "mf_england = {x:([],[],[],[]) for x in most_frequent}\n",
        "mf_scotland = {x:([],[],[],[]) for x in most_frequent}\n",
        "mf_australian = {x:([],[],[],[]) for x in most_frequent}\n",
        "dist_accents = {'us':mf_us,'canada':mf_canada,'indian':mf_indian,'african':mf_african,'england':mf_england,'scotland':mf_scotland,'australia':mf_australian}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kWnkRCuRF-G"
      },
      "outputs": [],
      "source": [
        "# print(target_transcript)\n",
        "# for file in trans_dict[target_transcript]:\n",
        "#     Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#     display(Audio(wav, rate=Fs))\n",
        "#     with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "#         file_attr = pickle.load(j)\n",
        "#     print(file_attr['output'], file_meta[file]['accent'])\n",
        "#     print(list(file_attr['attr dict'].keys()))\n",
        "#     #inp_grad_grapheme(file, grapheme_idx)\n",
        "#     print(file)\n",
        "#     print(grad_word_dist(file,2, 1))\n",
        "#     break\n",
        "valid_punctuation = string.punctuation.replace(\"'\",\"\")\n",
        "for t in transcripts:\n",
        "#     print(t)\n",
        "    \n",
        "    t_ = t.strip().upper()\n",
        "    t_ = t_.translate(str.maketrans({a:None for a in valid_punctuation }))\n",
        "    #print(t_)\n",
        "    t_list = t_.split()\n",
        "    true_nz_counts = {x:t_list.count(x) for x in most_frequent if t_list.count(x) > 0}\n",
        "    true_nz_indices = {x:[index for index, value in enumerate(t_list) if value == x] for x in true_nz_counts.keys()}\n",
        "    \n",
        "    for file in trans_dict[t]:\n",
        "        \n",
        "        try:   \n",
        "            with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "                file_attr = pickle.load(j)\n",
        "            op = file_attr['output'].replace('_', '')\n",
        "    #             print(op)\n",
        "            op_list = op.split()\n",
        "            accent = file_meta[file]['accent']\n",
        "            #print(accent,'------------------')\n",
        "            a_indices = {x:[index for index, value in enumerate(op_list) if value == x] for x in true_nz_counts.keys()}\n",
        "\n",
        "            for w in true_nz_counts.keys():\n",
        "                for idx in a_indices[w]:\n",
        "    #                     print('here')\n",
        "    #                     print(w)\n",
        "                    # compute condition for correctness\n",
        "                    distr, distr_wo = grad_clubbed_word(file, 2*idx, disable_prints=True)\n",
        "                    #print(distr)\n",
        "                    max_idx = np.argmax(np.asarray(distr))\n",
        "                    max_idx_wo = np.argmax(np.asarray(distr_wo))\n",
        "                    if(is_correct(op,t_,idx)):\n",
        "    #                         print('lol')\n",
        "    #                         print(true_nz_indices[w])\n",
        "    #                         print(a_indices[w].index(idx))\n",
        "                        idx2 = true_nz_indices[w][a_indices[w].index(idx)]\n",
        "                        wd1,e1,wd2,e2 = grad_word_dist(file,2*idx,idx2, taper= False)\n",
        "                        dist_accents[accent][w][0].append(wd1)\n",
        "                        dist_accents[accent][w][1].append(e1)\n",
        "                        if(np.isnan(e2/len(w))):\n",
        "                           print('encountered nan', e2, len(w))\n",
        "                           continue\n",
        "                        dist_accents[accent][w][2].append(e2/len(w))\n",
        "                        #print(wd2, e2)\n",
        "                        dist_accents[accent][w][3].append(e2)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpuwkyaXRF-G"
      },
      "outputs": [],
      "source": [
        "\n",
        "mf_us = {x:([],[],[],[]) for x in chosen}\n",
        "mf_canada = {x:([],[],[],[]) for x in chosen}\n",
        "mf_indian = {x:([],[],[],[]) for x in chosen}\n",
        "mf_african = {x:([],[],[],[]) for x in chosen}\n",
        "mf_england = {x:([],[],[],[]) for x in chosen}\n",
        "mf_scotland = {x:([],[],[],[]) for x in chosen}\n",
        "mf_australian = {x:([],[],[],[]) for x in chosen}\n",
        "dist_accents = {'us':mf_us,'canada':mf_canada,'indian':mf_indian,'african':mf_african,'england':mf_england,'scotland':mf_scotland,'australia':mf_australian}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToJ9Vx5ZRF-G"
      },
      "outputs": [],
      "source": [
        "# print(target_transcript)\n",
        "# for file in trans_dict[target_transcript]:\n",
        "#     Fs, wav = wavfile.read('my_data/MCV_validated_{}/wav/{}.wav'.format(file_meta[file]['accent'],file))\n",
        "#     display(Audio(wav, rate=Fs))\n",
        "#     with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "#         file_attr = pickle.load(j)\n",
        "#     print(file_attr['output'], file_meta[file]['accent'])\n",
        "#     print(list(file_attr['attr dict'].keys()))\n",
        "#     #inp_grad_grapheme(file, grapheme_idx)\n",
        "#     print(file)\n",
        "#     print(grad_word_dist(file,2, 1))\n",
        "#     break\n",
        "valid_punctuation = string.punctuation.replace(\"'\",\"\")\n",
        "most_frequent = chosen_words\n",
        "for t in transcripts:\n",
        "    \n",
        "    t_ = t.strip().upper()\n",
        "    t_ = t_.translate(str.maketrans({a:None for a in valid_punctuation }))\n",
        "    #print(t_)\n",
        "    t_list = t_.split()\n",
        "    true_nz_counts = {x:t_list.count(x) for x in most_frequent if t_list.count(x) > 0}\n",
        "    true_nz_indices = {x:[index for index, value in enumerate(t_list) if value == x] for x in true_nz_counts.keys()}\n",
        "    \n",
        "    for file in trans_dict[t]:\n",
        "        \n",
        "        try:   \n",
        "            with open('attribution/grad/{}.pickle'.format(file), 'rb') as j:\n",
        "                file_attr = pickle.load(j)\n",
        "            op = file_attr['output'].replace('_', '')\n",
        "    #             print(op)\n",
        "            op_list = op.split()\n",
        "            accent = file_meta[file]['accent']\n",
        "            #print(accent,'------------------')\n",
        "            a_indices = {x:[index for index, value in enumerate(op_list) if value == x] for x in true_nz_counts.keys()}\n",
        "\n",
        "            for w in true_nz_counts.keys():\n",
        "                for idx in a_indices[w]:\n",
        "    #                     print('here')\n",
        "    #                     print(w)\n",
        "                    # compute condition for correctness\n",
        "                    distr, distr_wo = grad_clubbed_word(file, 2*idx, disable_prints=True)\n",
        "                    #print(distr)\n",
        "                    max_idx = np.argmax(np.asarray(distr))\n",
        "                    max_idx_wo = np.argmax(np.asarray(distr_wo))\n",
        "                    if(is_correct(op,t_,idx)):\n",
        "    #                         print('lol')\n",
        "    #                         print(true_nz_indices[w])\n",
        "    #                         print(a_indices[w].index(idx))\n",
        "                        idx2 = true_nz_indices[w][a_indices[w].index(idx)]\n",
        "                        for l in range(len(hyphenate_word(w))):\n",
        "                            wd1,e1,wd2,e2 = grad_syll_dist(file,2*idx,idx2,l, taper= False)\n",
        "#                             dist_accents[accent][w][0].append(wd1)\n",
        "#                         dist_accents[accent][w][1].append(e1)\n",
        "                            if(np.isnan(e2)):\n",
        "                               print('encountered nan', e2)\n",
        "                               continue\n",
        "                            #dist_accents[accent][w][2].append(e2/len(w))\n",
        "                            #print(wd2, e2)\n",
        "                            #print(dist_accents[accent])\n",
        "                            #print([hyphenate_word(w)[l]])\n",
        "                            dist_accents[accent][hyphenate_word(w)[l]][3].append(e2)\n",
        "                            #print(dist_accents[accent])\n",
        "                            #break\n",
        "                    \n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBdUmeFJRF-H",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "acc_chosen = {k:{a:0 for a in dist_accents.keys()} for k in chosen}\n",
        "for a in dist_accents.keys():\n",
        "#     print(a)\n",
        "    #print(chosen)\n",
        "    acc = {k:[] for k in chosen}\n",
        "    #a = 'indian'\n",
        "    #print(mf_accents[a].keys())\n",
        "    for w in chosen:\n",
        "        #print(len(acc[2]))\n",
        "        #print(len(dist_accents[a][w][2]))\n",
        "#         acc[0].append(np.asarray(dist_accents[a][w][0]).mean())\n",
        "#         acc[1].append(np.asarray(dist_accents[a][w][1]).mean())\n",
        "        inter = np.asarray(dist_accents[a][w][3]).mean()\n",
        "        if(not np.isnan(inter)):\n",
        "            acc[w].append(inter)\n",
        "            acc_chosen[w][a] = inter\n",
        "        #acc[3].append(np.asarray(dist_accents[a][w][3]).mean())\n",
        "    \n",
        "#         acc[word_cluster[w]].extend(np.random.choice(np.asarray(dist_accents[a][w][2]),int(min_dist[most_frequent.index(w)]), replace = False))\n",
        "#         acc[word_cluster[w]].append(np.random.choice(np.asarray(dist_accents[a][w][2]),int(min_dist[most_frequent.index(w)]), replace = False).mean())\n",
        "#         acc[3].append(np.asarray(dist_accents[a][w][3]).mean())\n",
        "    #print(len(np.asarray(acc[2])))\n",
        "#     print(a, acc)\n",
        "#     print('------------------------')\n",
        "print('___________________________')\n",
        "for l in acc_chosen.keys():\n",
        "    print(l, acc_chosen[l])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9QszI8FRF-H"
      },
      "source": [
        "### <font color=\"00ff00\">  **Clustering words based on number of phones**</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZDKUcRbRF-H"
      },
      "outputs": [],
      "source": [
        "nltk.download('cmudict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYNQZEDxRF-I"
      },
      "outputs": [],
      "source": [
        "def get_cluster(num):\n",
        "    if(num < 3):\n",
        "        return 0\n",
        "    elif(num < 4):\n",
        "        return 1\n",
        "    else: return 2\n",
        "# def get_cluster(num):\n",
        "#     if(num < 3):\n",
        "#         return 0\n",
        "#     elif(num < 5):\n",
        "#         return 1\n",
        "#     else: return 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJinO0HaRF-I",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "arpabet = nltk.corpus.cmudict.dict()\n",
        "word_phn = np.zeros(len(most_frequent))\n",
        "word_len = np.zeros(len(most_frequent))\n",
        "for w in most_frequent:\n",
        "    word_phn[most_frequent.index(w)] = len(arpabet[w.lower()][0])\n",
        "    #break\n",
        "print(word_phn)\n",
        "for w in most_frequent:\n",
        "    word_len[most_frequent.index(w)] = len(w)\n",
        "    #break\n",
        "# print(word_phn)\n",
        "print(word_len)\n",
        "print(most_frequent)\n",
        "word_cluster = {x: get_cluster(word_phn[most_frequent.index(x)]) for x in most_frequent}\n",
        "print(word_cluster)\n",
        "print(word_phn[most_frequent.index(w)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72pV6nDORF-I"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4frXtXXRF-I"
      },
      "outputs": [],
      "source": [
        "min_dist = np.ones(len(most_frequent))*10000\n",
        "for w in most_frequent:\n",
        "    #print(w)\n",
        "    \n",
        "    for a in dist_accents.keys():\n",
        "       \n",
        "        min_dist[most_frequent.index(w)] = min(len(dist_accents[a][w][2]), min_dist[most_frequent.index(w)])\n",
        "        \n",
        "print(min_dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqtJva_5RF-J"
      },
      "source": [
        "##### <font color=white> **Report EMD based on wd2**</font> \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuD5Sls9RF-J"
      },
      "outputs": [],
      "source": [
        "for a in dist_accents.keys():\n",
        "#     print(a)\n",
        "    acc = ([],[],[],[])\n",
        "    #a = 'indian'\n",
        "    for w in mf_accents[a].keys():\n",
        "        #print(len(acc[2]))\n",
        "        #print(len(dist_accents[a][w][2]))\n",
        "#         acc[0].append(np.asarray(dist_accents[a][w][0]).mean())\n",
        "#         acc[1].append(np.asarray(dist_accents[a][w][1]).mean())\n",
        "        acc[word_cluster[w]].append(np.asarray(dist_accents[a][w][3]).mean())\n",
        "        acc[3].append(np.asarray(dist_accents[a][w][3]).mean())\n",
        "    \n",
        "#         acc[word_cluster[w]].extend(np.random.choice(np.asarray(dist_accents[a][w][2]),int(min_dist[most_frequent.index(w)]), replace = False))\n",
        "#         acc[word_cluster[w]].append(np.random.choice(np.asarray(dist_accents[a][w][2]),int(min_dist[most_frequent.index(w)]), replace = False).mean())\n",
        "#         acc[3].append(np.asarray(dist_accents[a][w][3]).mean())\n",
        "    #print(len(np.asarray(acc[2])))\n",
        "    print(a, np.asarray(acc[0]).mean().round(2), np.asarray(acc[1]).mean().round(2), np.asarray(acc[2]).mean().round(2), np.asarray(acc[3]).mean().round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBAsy88qRF-J"
      },
      "source": [
        "##### <font color=white> **Report EMD based on wd2**</font> \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXsD894xRF-J"
      },
      "outputs": [],
      "source": [
        "with open('syll.pickle','rb') as s:\n",
        "    syllables = pickle.load(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCdpUf_2RF-J"
      },
      "outputs": [],
      "source": [
        "syll_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av8Nk5DvRF-K"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "seg = 0\n",
        "for w in syllables.keys():\n",
        "    \n",
        "    \n",
        "    wl = w.lower()\n",
        "    hyp = hyphenate_word(wl)\n",
        "    for h in hyp:\n",
        "        if(h not in syll_dict.keys()):\n",
        "            syll_dict[h]={'count':my_freq[my_freq_words.index(w)][1],'words':[w]}\n",
        "        else:\n",
        "            syll_dict[h]['count'] += my_freq[my_freq_words.index(w)][1]\n",
        "            syll_dict[h]['words'].append(w)\n",
        "            \n",
        "    try:\n",
        "        if(len(syllables[w][0]['syll'] ) == len(hyp)):\n",
        "            seg += len(hyp)\n",
        "            syllables[w][0]['splt'] = hyp\n",
        "        else:\n",
        "            count+=1\n",
        "            print(w, count)\n",
        "    except:\n",
        "        count += 1\n",
        "        print(w)\n",
        "#print(seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17vFFysGRF-K"
      },
      "outputs": [],
      "source": [
        "print(syll_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzXrrshrRF-M"
      },
      "outputs": [],
      "source": [
        "chosen = [k.upper() for k, v in sorted(syll_dict.items(), key=lambda item: item[1]['count'])][::-1][:75]\n",
        "print(chosen)\n",
        "chosen_words = []\n",
        "for c in chosen:\n",
        "    chosen_words.extend(syll_dict[c.lower()]['words'] )\n",
        "chosen_words = list(set(chosen_words))\n",
        "print(chosen_words)\n",
        "print(len(chosen_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE6l-kglRF-M"
      },
      "outputs": [],
      "source": [
        "syllables['CREATIVE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC7LGSA3RF-M"
      },
      "outputs": [],
      "source": [
        "syll_dict['minder']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLrTAWw5RF-N"
      },
      "outputs": [],
      "source": [
        "len(list(syllables.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skar_VOHRF-N"
      },
      "outputs": [],
      "source": [
        "my_freq = allWordDist.most_common(1256)\n",
        "my_freq_words = [w[0] for w in my_freq]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}