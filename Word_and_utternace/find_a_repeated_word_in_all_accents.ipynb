{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Xt5RMCPIAW",
        "outputId": "9a8db331-fa42-4857-befc-262713a742d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert a word to test it please? aaa\n",
            "unfortunately, the Word \"aaa\" are ***NOT found in all German accents\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "! cp /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/results.json   /content/results.json\n",
        "#@title ###**According to a given word, this code shows and writes in which Audio files and which Accent this given word is located:**\n",
        "\n",
        "###########################################################################################################################################################\n",
        "########### creat a Dataframe called \"dataset_audiofilename_transcript_accent\" contains all audiofilename and thier 'transcript' and 'test_file' /Accent####\n",
        "###########################################################################################################################################################\n",
        "list_dataset_test_=['test_at.txt','test_gb.txt','test_it.txt','test_de_al.txt','test_fr.txt','test_de_ni.txt','test_ch.txt',\n",
        "               'test_de.txt','test_us.txt','test_ca.txt','test_ru.txt']\n",
        "list_dataset_test_accent=['Österreichisches Deutsch','Britisches Deutsch','Italienisch Deutsch','Alemannische Färbung,Schweizer Standart Deutsch',\n",
        "'Französisch Deutsch','Niederländisch Deutsch','Schweizerdeutsch','Deutschland Deutsch','Amerikanisches Deutsch','Kanadisches Deutsch','Russisch Deutsch']\n",
        "\n",
        "data_dict_accent_duration  = dict(zip( list_dataset_test_, list_dataset_test_accent))  \n",
        "\n",
        "# create an empty set to store the words that meet all 11 accents\n",
        "words = set()\n",
        "accent_long_set=set()\n",
        "accent_long_list=[]\n",
        " \n",
        "\n",
        "### here is the required_word\n",
        "# required_word=\"Start\"\n",
        "required_word=input('Insert a word to test it please? ')\n",
        "newfile=0\n",
        "\n",
        "# dict_audiofilename_transcript_accent=[]\n",
        "# To find out the Audio file's Accent\n",
        "list_test_accent_txt_values=[]\n",
        "list_test_accent_txt_keys=[]\n",
        "list_test_file=[]\n",
        "list_accent_long=[]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  Dict_results = json.load(open('results.json'))\n",
        "  for test_file in Dict_results:\n",
        "    # print(test_file)\n",
        "    list_test_accent_txt_values_temp = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
        "    list_test_accent_txt_keys_temp=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
        "    list_test_file_temp=[test_file for v in Dict_results[test_file].values()]\n",
        "\n",
        "# creat a Dataframe called  dataset_audiofilename_transcript_accent contains all audiofilename and thier 'transcript' and 'test_file' /Accent\n",
        "    list_test_accent_txt_values.extend(list_test_accent_txt_values_temp)\n",
        "    list_test_accent_txt_keys.extend(list_test_accent_txt_keys_temp)\n",
        "    list_test_file.extend(list_test_file_temp)\n",
        "    keys=['audiofilename','transcript','test_file']\n",
        "    trans_dict_test_file_result = dict(zip(keys,[list_test_accent_txt_keys, list_test_accent_txt_values,list_test_file]))\n",
        "    \n",
        "dataset_audiofilename_transcript_accent = pd.DataFrame(trans_dict_test_file_result)\n",
        " \n",
        "\n",
        "for key, row in dataset_audiofilename_transcript_accent.iterrows():\n",
        "  if required_word in row['transcript']:\n",
        "\n",
        "# to show the full name accent of the founded result \n",
        "    for keys_accent_long_i, values_accent_long_i in data_dict_accent_duration.items():\n",
        "      if dataset_audiofilename_transcript_accent.test_file[key]==keys_accent_long_i:\n",
        "        # print()\n",
        "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        # f'*** Accent ={dataset_audiofilename_transcript_accent.test_file[key]}')\n",
        "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
        "        #       f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}')\n",
        "        accent_long_list.append(data_dict_accent_duration[keys_accent_long_i])\n",
        "        accent_long_str = ', '.join(accent_long_list)\n",
        "        accent_long_set=set(accent_long_str.split(', '))\n",
        "        # print(accent_long_str)\n",
        "\n",
        "        # get the accents for the current row\n",
        "        # accents = set(row['test_file'].split())\n",
        "        # accents = set(accent_long_set.split())\n",
        "        # print(len(accents))\n",
        "        # print('*'*60)\n",
        "        # check if the set of accents contains all 11 accents\n",
        "\n",
        "if len(accent_long_set) == 11:\n",
        "  print('*'*60)\n",
        "  print(f'Perfect, the Word {required_word} are found in all German accents')\n",
        "  print('*'*60)\n",
        "else:\n",
        "  print(f'unfortunately, the Word \"{required_word}\" are ***NOT found in all German accents')\n",
        "        # add the word to the set of words that meet all 11 accents\n",
        "#             words.add(row['transcript'])\n",
        "\n",
        "# # # print the words that meet all 11 accents\n",
        "# print('*'*60)\n",
        "# print(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-4i3FK4vPM7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}