{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change this if you don't want the data to be extracted in the current directory.\n",
    "data_dir = '.'\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "from scipy.io import wavfile\n",
    "from itertools import chain \n",
    "import string\n",
    "import Levenshtein as Lev\n",
    "from itertools import groupby\n",
    "import scipy.stats as st\n",
    "from scipy import signal\n",
    "import nltk\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from pyemd import emd\n",
    "from hyphenate import hyphenate_word\n",
    "from itertools import islice \n",
    "from collections import OrderedDict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "########### set the Data files paths on Conda Notebook on Ubuntu #################### \n",
    "\n",
    "### \n",
    "os.chdir('/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De')\n",
    "main_path=os.getcwd()\n",
    "\n",
    "if not os.path.exists(main_path+'/Data_results'):\n",
    "  os.makedirs(main_path+'/Data_results')\n",
    "\n",
    "if not os.path.exists(main_path+'/Figures_results'):\n",
    "  os.makedirs(main_path+'/Figures_results')\n",
    "\n",
    "Data_path=main_path+'/Data/'\n",
    "Data_results_path=main_path+'/Data_results/'\n",
    "json_file_path=Data_path+'results.json'\n",
    "json_file_path_small=Data_path+'results_small.json'\n",
    "validated_tsv_path=Data_path+'validated.tsv'\n",
    "validated_tsv_path_small=Data_path+'validated_small.tsv'\n",
    " \n",
    "\n",
    "validated_en_tsv_path=main_path+'/DeepSpeech/data/validated.tsv'\n",
    "validated_en_tsv_path_small=main_path+'/DeepSpeech/data/validated_small.tsv'\n",
    "\n",
    " \n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Making `test_manifest.csv` file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3035918604.py, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 86\u001b[0;36m\u001b[0m\n\u001b[0;31m    with open(main_path+f'/DeepSpeech/data/test_manifest_'{Lang}''.csv', \"w\", newline=\"\") as csvfile:\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#@title create the Sentence's text files according to their existing wave Audio files##########\n",
    "###############################################################################################\n",
    "# in the wav source mentioned folder and store them in main_path+'/DeepSpeech/data/text' ######\n",
    "###############################################################################################\n",
    "\n",
    "'''\n",
    "##########################################################################################\n",
    "Inputs will be the wave files, validated.tsv  ############################################\n",
    "Outputs will be Text files,test_manifest.csv contains /path/to/audio.wav,/path/to/audio.txt\n",
    "##########################################################################################\n",
    "''' \n",
    "Lang='De'  # De or En\n",
    "\n",
    "audio_file_id_list=[]\n",
    "audio_file_id_txt=[]\n",
    "\n",
    "\n",
    "\n",
    "# set the paths for audio files and text files\n",
    "if Lang=='De':\n",
    "    audio_path = main_path+\"/audio/wav/audio_De_08042023/\" # active this line for the German Accents\n",
    "    text_path = main_path+\"/DeepSpeech/data/text/\"\n",
    "    tsv_en_data = pd.read_csv( validated_tsv_path_small, sep='\\t') # active this line for the German Accents\n",
    "    #Open the TSV file and read its contents\n",
    "elif Lang=='En':\n",
    "    \n",
    "    audio_path = main_path+\"/audio/wav/audio_wav_files_En/\" # active this line for the English Accents\n",
    "    text_path = main_path+\"/DeepSpeech/data/text/\"            \n",
    "    tsv_en_data = pd.read_csv( validated_en_tsv_path_small, sep='\\t') # active this line for the English Accents\n",
    "\n",
    "tsv_en_data.drop(tsv_en_data[(tsv_en_data['path'].isna())].index, inplace=True)\n",
    "\n",
    "# create text folder inside DeepSpeech\n",
    "if not os.path.exists(main_path+'/DeepSpeech/data/text'):\n",
    "    os.makedirs(main_path+'/DeepSpeech/data/text')\n",
    "\n",
    "# Use glob to get a list of all wav files in the folder\n",
    "wav_files = glob.glob(audio_path+\"/*.wav\")\n",
    " \n",
    "# Loop through the list of MP3 files\n",
    "for wav_file in wav_files:\n",
    "    wav_file_id=re.split(r'[/|/|.]',wav_file)[9]\n",
    "\n",
    "    for row, content in tsv_en_data.iterrows():\n",
    "        # Extract the sentence and path from the current row\n",
    "        sentence = content['sentence']\n",
    "        audio_file_id = re.split(r'[.]',content['path'])[0]  \n",
    "        if wav_file_id== audio_file_id:\n",
    "\n",
    "            # Create the text file name based on the path column\n",
    "            text_file_name = os.path.splitext(os.path.basename(audio_file_id))[0] + '.txt'\n",
    "\n",
    "            # Create the full path to the text file\n",
    "            text_file_path = os.path.join('DeepSpeech', 'data', 'text', text_file_name)\n",
    "            # or\n",
    "            #  text_file_path = text_path\n",
    "\n",
    "            # Write the sentence to the text file\n",
    "            with open(main_path+'/'+text_file_path, 'w') as text_file:\n",
    "                text_file.write(sentence)\n",
    "\n",
    "            '''Dataset that loads tensors via a csv containing file paths to audio files and transcripts separated by\n",
    "            a comma. Each new line is a different sample. Example below:\n",
    "            /path/to/audio.wav,/path/to/audio.txt'''\n",
    "\n",
    "#####################################################################################\n",
    "# get a list of all the audio,text files in the audio path , text path ##############\n",
    "# create the Manifest CSV file from them     ########################################      \n",
    "#####################################################################################\n",
    "# get a list of all the audio files in the audio path\n",
    "audio_files = [f for f in os.listdir(audio_path) if f.endswith(\".wav\")]\n",
    "\n",
    "# create an empty list to store the audio and text file paths\n",
    "file_paths = []\n",
    "\n",
    "# loop through the audio files and check if there is a matching text file\n",
    "for audio_file in audio_files:\n",
    "    audio_name = os.path.splitext(audio_file)[0] # get the name of the audio file without the extension\n",
    "    text_file = text_path + audio_name + \".txt\" # create the path for the matching text file\n",
    "    \n",
    "    # check if the text file exists\n",
    "    if os.path.isfile(text_file):\n",
    "        file_paths.append([audio_path + audio_file, text_file])\n",
    "\n",
    "# create a CSV file with the list of file paths\n",
    "with open(main_path+'/DeepSpeech/data/test_manifest_'+Lang+'.csv', \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # write a columns label\n",
    "    # writer.writerow([\"Audio File\", \"Text File\"])\n",
    "    # write a columns contents\n",
    "    writer.writerows(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
