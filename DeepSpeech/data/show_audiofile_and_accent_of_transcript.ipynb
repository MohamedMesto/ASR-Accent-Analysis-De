{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change this if you don't want the data to be extracted in the current directory.\n",
    "data_dir = '.'\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "from scipy.io import wavfile\n",
    "from itertools import chain \n",
    "import string\n",
    "import Levenshtein as Lev\n",
    "from itertools import groupby\n",
    "import scipy.stats as st\n",
    "from scipy import signal\n",
    "import nltk\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from pyemd import emd\n",
    "from hyphenate import hyphenate_word\n",
    "from itertools import islice \n",
    "from collections import OrderedDict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "########### set the Data files paths on Conda Notebook on Ubuntu #################### \n",
    "\n",
    "### \n",
    "os.chdir('/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De')\n",
    "main_path=os.getcwd()\n",
    "\n",
    "if not os.path.exists(main_path+'/Data_results'):\n",
    "  os.makedirs(main_path+'/Data_results')\n",
    "\n",
    "if not os.path.exists(main_path+'/Figures_results'):\n",
    "  os.makedirs(main_path+'/Figures_results')\n",
    "\n",
    "Data_path=main_path+'/Data/'\n",
    "Data_results_path=main_path+'/Data_results/'\n",
    "json_file_path=Data_path+'results.json'\n",
    "json_file_path_small=Data_path+'results_small.json'\n",
    "validated_tsv_path=Data_path+'validated.tsv'\n",
    "validated_tsv_path_small=Data_path+'validated_small.tsv'\n",
    " \n",
    "\n",
    "validated_en_tsv_path=main_path+'/DeepSpeech/data/validated.tsv'\n",
    "validated_en_tsv_path_small=main_path+'/DeepSpeech/data/validated_small.tsv'\n",
    "\n",
    " \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "common_voice_de_17686048 findest du dich allein in braunschweig zurecht *** Accent is Schweizerdeutsch\n",
      "\n",
      "common_voice_de_17650552 findest du dich allein in braunschweig zurecht *** Accent is Deutschland Deutsch\n"
     ]
    }
   ],
   "source": [
    "#@title ###**According to a given utterance, this code shows and writes in which Audio files and which Accent this given utterance is located:**\n",
    "\n",
    "###########################################################################################################################################################\n",
    "########### creat a Dataframe called \"dataset_audiofilename_transcript_accent\" contains all audiofilename and thier 'transcript' and 'test_file' /Accent####\n",
    "###########################################################################################################################################################\n",
    "list_dataset_test_=['test_at.txt','test_gb.txt','test_it.txt','test_de_al.txt','test_fr.txt','test_de_ni.txt','test_ch.txt',\n",
    "               'test_de.txt','test_us.txt','test_ca.txt','test_ru.txt']\n",
    "list_dataset_test_accent=['Österreichisches Deutsch','Britisches Deutsch','Italienisch Deutsch','Alemannische Färbung,Schweizer Standart Deutsch',\n",
    "'Französisch Deutsch','Niederländisch Deutsch','Schweizerdeutsch','Deutschland Deutsch','Amerikanisches Deutsch','Kanadisches Deutsch','Russisch Deutsch']\n",
    "\n",
    "data_dict_accent_duration  = dict(zip( list_dataset_test_, list_dataset_test_accent))  \n",
    "\n",
    "\n",
    "### here is the required_utterance\n",
    "required_utterance=\"findest du dich allein in braunschweig zurecht\"\n",
    "newfile=0\n",
    "# dict_audiofilename_transcript_accent=[]\n",
    "# To find out the Audio file's Accent\n",
    "list_test_accent_txt_values=[]\n",
    "list_test_accent_txt_keys=[]\n",
    "list_test_file=[]\n",
    "list_accent_long=[]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # Dict_results = json.load(open(json_file_path))\n",
    "  with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    Dict_results = json.load(f)\n",
    "\n",
    "  for test_file in Dict_results:\n",
    "    # print(test_file)\n",
    "    list_test_accent_txt_values_temp = [v[\"reference\"] for v in Dict_results[test_file].values()]\n",
    "    list_test_accent_txt_keys_temp=[re.split(r'[.|/]',k)[9] for k in Dict_results[test_file].keys()]\n",
    "    list_test_file_temp=[test_file for v in Dict_results[test_file].values()]\n",
    "\n",
    "# creat a Dataframe called  dataset_audiofilename_transcript_accent contains all audiofilename and thier 'transcript' and 'test_file' /Accent\n",
    "    list_test_accent_txt_values.extend(list_test_accent_txt_values_temp)\n",
    "    list_test_accent_txt_keys.extend(list_test_accent_txt_keys_temp)\n",
    "    list_test_file.extend(list_test_file_temp)\n",
    "    keys=['audiofilename','transcript','test_file']\n",
    "    trans_dict_test_file_result = dict(zip(keys,[list_test_accent_txt_keys, list_test_accent_txt_values,list_test_file]))\n",
    "    \n",
    "dataset_audiofilename_transcript_accent = pd.DataFrame(trans_dict_test_file_result)\n",
    "\n",
    "#############################################################################################\n",
    "##### Show and write which Audio files and which Accent the given word is located ###########\n",
    "\n",
    "for key, value in dataset_audiofilename_transcript_accent['transcript'].items():\n",
    "  if required_utterance in value:\n",
    "\n",
    "# to show the full name accent of the founded result \n",
    "    for keys_accent_long_i, values_accent_long_i in data_dict_accent_duration.items():\n",
    "      if dataset_audiofilename_transcript_accent.test_file[key]==keys_accent_long_i:\n",
    "        print()\n",
    "        # print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
    "        # f'*** Accent ={dataset_audiofilename_transcript_accent.test_file[key]}')\n",
    "        print(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
    "              f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}')\n",
    "\n",
    "\n",
    "        # # Alternative way (for speed performance) to export the Audio files numbers and thiers Acccent to an external file\n",
    "        # # os.mkdir('/content/audiofilenames_transcript')\n",
    "\n",
    "        # if newfile==0:\n",
    "        #   dataset_accent_write_file = open(f'audiofilenames_transcript_accent_of_an_utterance.txt','w')\n",
    "        #   newfile=1\n",
    "        # else:\n",
    "        #   dataset_accent_write_file = open(f'audiofilenames_transcript_accent_of_an_utterance.txt','a')\n",
    "        #   dataset_accent_write_file.write(dataset_audiofilename_transcript_accent.audiofilename[key],dataset_audiofilename_transcript_accent.transcript[key],\n",
    "        #       f'*** Accent is {data_dict_accent_duration[keys_accent_long_i]}\\n')\n",
    "        #   dataset_accent_write_file.close()\n",
    "        #   # ! cp /content/audiofilenames_transcript/*.txt /content/drive/MyDrive/QU-DFKI-Thesis-ASR/Experimentation/data/test_data/audiofilenames_transcript/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
