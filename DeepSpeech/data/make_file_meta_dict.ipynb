{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change this if you don't want the data to be extracted in the current directory.\n",
    "data_dir = '.'\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "from scipy.io import wavfile\n",
    "from itertools import chain \n",
    "import string\n",
    "import Levenshtein as Lev\n",
    "from itertools import groupby\n",
    "import scipy.stats as st\n",
    "from scipy import signal\n",
    "import nltk\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from pyemd import emd\n",
    "from hyphenate import hyphenate_word\n",
    "from itertools import islice \n",
    "from collections import OrderedDict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "########### set the Data files paths on Conda Notebook on Ubuntu #################### \n",
    "\n",
    "### \n",
    "os.chdir('/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De')\n",
    "main_path=os.getcwd()\n",
    "\n",
    "if not os.path.exists(main_path+'/Data_results'):\n",
    "  os.makedirs(main_path+'/Data_results')\n",
    "\n",
    "if not os.path.exists(main_path+'/Figures_results'):\n",
    "  os.makedirs(main_path+'/Figures_results')\n",
    "\n",
    "Data_path=main_path+'/Data/'\n",
    "Data_results_path=main_path+'/Data_results/'\n",
    "json_file_path=Data_path+'results.json'\n",
    "json_file_path_small=Data_path+'results_small.json'\n",
    "validated_tsv_path=Data_path+'validated.tsv'\n",
    "validated_tsv_path_small=Data_path+'validated_small.tsv'\n",
    " \n",
    "\n",
    "validated_en_tsv_path=main_path+'/DeepSpeech/data/validated.tsv'\n",
    "validated_en_tsv_path_small=main_path+'/DeepSpeech/data/validated_small.tsv'\n",
    "\n",
    " \n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=white> **Creating a `En` dictionary `file_meta` for the Audio files , Accents** </font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Creat a EN dictionary for the Audio files , Accents#######\n",
    "###################################################################\n",
    "\n",
    "# initialize an empty dictionary\n",
    "file_meta = {}\n",
    "\n",
    "# read the TSV file\n",
    "with open(validated_en_tsv_path_small, 'r') as f:\n",
    "    # skip the header row\n",
    "    next(f)\n",
    "    # iterate over the remaining rows\n",
    "    for line in f:\n",
    "        # split the line into columns\n",
    "        cols = line.strip().split('\\t')\n",
    "        # extract the relevant columns\n",
    "        filename = cols[1].split('.')[0]\n",
    "        accent = cols[7]\n",
    "        transcript = cols[2]\n",
    "        # create a dictionary for this file\n",
    "        file_dict = {'accent': accent, 'transcript': transcript}\n",
    "        # add the dictionary to the file_meta dictionary\n",
    "        file_meta[filename] = file_dict\n",
    "        \n",
    "\n",
    "        # Open a new CSV file in write mode\n",
    "with open(main_path+'/DeepSpeech/data/file_meta.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(file_meta.keys())\n",
    "\n",
    "    # Write the values row\n",
    "    writer.writerow(file_meta.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': 'australia',\n",
       " 'transcript': 'The burning fire had been extinguished.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_en_533247\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'australia'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_en_533247\"]['accent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The burning fire had been extinguished.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_en_533247\"]['transcript']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=white> **Creating a `De` dictionary `file_meta` for the Audio files , Accents** </font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Creat a De dictionary for the Audio files , Accents#######\n",
    "###################################################################\n",
    "\n",
    "# initialize an empty dictionary\n",
    "file_meta = {}\n",
    "\n",
    "# read the TSV file\n",
    "# with open(validated_tsv_path_small, 'r') as f:\n",
    "with open(validated_tsv_path_small, 'r') as f:\n",
    "    # skip the header row\n",
    "    next(f)\n",
    "    # iterate over the remaining rows\n",
    "    for line in f:\n",
    "        # split the line into columns\n",
    "        cols = line.strip().split('\\t')\n",
    "        # extract the relevant columns\n",
    "        filename = cols[1].split('.')[0]\n",
    "        accent = cols[7]\n",
    "        transcript = cols[2]\n",
    "        # create a dictionary for this file\n",
    "        file_dict = {'accent': accent, 'transcript': transcript}\n",
    "        # add the dictionary to the file_meta dictionary\n",
    "        file_meta[filename] = file_dict\n",
    "        \n",
    "\n",
    "        # Open a new CSV file in write mode\n",
    "with open(main_path+'/DeepSpeech/data/file_meta.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(file_meta.keys())\n",
    "\n",
    "    # Write the values row\n",
    "    writer.writerow(file_meta.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': 'Österreichisches Deutsch',\n",
       " 'transcript': 'Gerschler wurde von seinen Großeltern und einer Tante erzogen.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_de_30676740\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Österreichisches Deutsch'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_de_30676740\"]['accent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gerschler wurde von seinen Großeltern und einer Tante erzogen.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_de_30676740\"]['transcript']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading `Phones` and `End_times` from the `Textgrid` of multiple file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- IntervalTier Example -------\n",
      "common_voice_de_28897371.TextGrid - export Phnes and End_times Done\n",
      "------- IntervalTier Example -------\n",
      "common_voice_de_27916918.TextGrid - export Phnes and End_times Done\n",
      "------- IntervalTier Example -------\n",
      "common_voice_de_30676740.TextGrid - export Phnes and End_times Done\n"
     ]
    }
   ],
   "source": [
    "import textgrid\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#@title  Process \"align.json\" files contents and import end_times,phones to pass it to ###\n",
    "\t\t################################## file_meta dict ########################################\n",
    "\t\t##########################################################################################\n",
    "\t\t \n",
    "\n",
    "'''\n",
    "##########################################################################################\n",
    "##### Input : the output align.json of an Audio (From Montreal Forced Aligner Output)\n",
    "##### Output:\n",
    "##########################################################################################\n",
    "'''\n",
    "\n",
    "# dir_path = os.path.dirname(os.path.abspath(__file__))\n",
    "############### # in this case should the textgrid ile located at the same working file\n",
    "############### AttributionAnalysis_De_NB18042023.ipynb\n",
    "\n",
    "Lan ='De'\n",
    "\n",
    "if Lan =='De':\n",
    "    folder_path = main_path+'/DeepSpeech/data/textgrid/' # replace with the actual path of your directory\n",
    "elif Lan=='En':\n",
    "    folder_path = main_path+'/DeepSpeech/data/textgrid_En/' # replace with the actual path of your directory\n",
    "\n",
    "extension = '.TextGrid'\n",
    "\n",
    "# Get a list of all files with the specified extension in the folder\n",
    "files = glob.glob(os.path.join(folder_path, '*' + extension))\n",
    "\n",
    "# Loop through the files and print their names\n",
    "for audio_file_textgrid in files:\n",
    "    # print(os.path.basename(file))\n",
    "    file_name=os.path.basename(audio_file_textgrid)\n",
    "# dir_path =main_path+'/DeepSpeech/data/textgrid/'\n",
    "# file_name = \"common_voice_de_30676740\"\n",
    "    # file_path = dir_path + \"/\" + file_name\n",
    "\n",
    "\n",
    "    # tg = textgrid.TextGrid.fromFile(dir_path + \"/\" + file_name + \".TextGrid\")\n",
    "    tg = textgrid.TextGrid.fromFile(folder_path + \"/\" + file_name)\n",
    "    csv_input = [[], []]\n",
    "\n",
    "\n",
    "    print(\"------- IntervalTier Example -------\")\n",
    "    print(os.path.basename(audio_file_textgrid),'- export Phnes and End_times Done')\n",
    "    file_name_id=os.path.splitext(os.path.basename(audio_file_textgrid))[0]\n",
    "    t = tg.tiers\n",
    "    for i in range (len(tg.getNames())): \n",
    "        if (tg[i].name == \"phones\"): \n",
    "            # print(tg[i].name)\n",
    "            for j in range (len(tg[i].intervals)):\n",
    "                # print(tg[i][j].mark)\n",
    "                csv_input[0].append(tg[i][j].mark)\n",
    "                csv_input[1].append(tg[i][j].maxTime)\n",
    "\n",
    "        ################################################################################################                \n",
    "        # update the file_meta dictionary with the phone transcriptions and their corresponding end times\n",
    "                file_meta[file_name_id]['phones'] = csv_input[0]\n",
    "                file_meta[file_name_id]['end_times'] = csv_input[1]\n",
    "\n",
    "    with open(folder_path + \"/\" + file_name_id +\".csv\", 'w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(csv_input)\n",
    "\n",
    "\n",
    "   \n",
    "    # save the updated file_meta dictionary to a CSV file\n",
    "    with open(main_path+'/DeepSpeech/data/file_meta_end_phones_'+Lan+'.csv', 'w', newline='') as csv_file:\n",
    "  \n",
    "        # Define the fieldnames of the CSV file\n",
    "        fieldnames = list(file_meta.keys())\n",
    "\n",
    "        # Create a writer object\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write the data rows\n",
    "        writer.writerow(file_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'spn',\n",
       " 'v',\n",
       " 'ʊ',\n",
       " 'ʁ',\n",
       " 'd',\n",
       " 'ə',\n",
       " 'f',\n",
       " 'ɔ',\n",
       " 'n',\n",
       " 'z',\n",
       " 'aj',\n",
       " 'n',\n",
       " 'n̩',\n",
       " 'spn',\n",
       " 'ʊ',\n",
       " 'n',\n",
       " 't',\n",
       " 'aj',\n",
       " 'n',\n",
       " 'ɐ',\n",
       " 'tʰ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'tʰ',\n",
       " 'ə',\n",
       " 'ɛ',\n",
       " 'ɐ',\n",
       " 'ts',\n",
       " 'oː',\n",
       " 'ɡ',\n",
       " 'n̩',\n",
       " '']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_de_30676740\"]['phones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.09,\n",
       " 1.68,\n",
       " 2.0,\n",
       " 2.07,\n",
       " 2.08,\n",
       " 2.13,\n",
       " 2.17,\n",
       " 2.26,\n",
       " 2.31,\n",
       " 2.4,\n",
       " 2.51,\n",
       " 2.6,\n",
       " 2.66,\n",
       " 2.73,\n",
       " 3.52,\n",
       " 3.57,\n",
       " 3.62,\n",
       " 3.69,\n",
       " 3.8,\n",
       " 3.85,\n",
       " 3.91,\n",
       " 4.06,\n",
       " 4.12,\n",
       " 4.18,\n",
       " 4.32,\n",
       " 4.36,\n",
       " 4.43,\n",
       " 4.47,\n",
       " 4.64,\n",
       " 4.77,\n",
       " 4.83,\n",
       " 4.96,\n",
       " 6.264]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_meta[\"common_voice_de_30676740\"]['end_times'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
