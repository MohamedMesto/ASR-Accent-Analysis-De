{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "from scipy.io import wavfile\n",
    "from itertools import chain \n",
    "import string\n",
    "import Levenshtein as Lev\n",
    "from itertools import groupby\n",
    "import scipy.stats as st\n",
    "from scipy import signal\n",
    "import nltk\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from pyemd import emd\n",
    "from hyphenate import hyphenate_word\n",
    "from itertools import islice \n",
    "from collections import OrderedDict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "########### set the Data files paths on Conda Notebook on Ubuntu #################### \n",
    "\n",
    "### \n",
    "os.chdir('/home/mmm2050/QU_DFKI_Thesis/Experimentation/ASR_Accent_Analysis_De')\n",
    "main_path=os.getcwd()\n",
    "\n",
    "if not os.path.exists(main_path+'/Data_results'):\n",
    "  os.makedirs(main_path+'/Data_results')\n",
    "\n",
    "if not os.path.exists(main_path+'/Figures_results'):\n",
    "  os.makedirs(main_path+'/Figures_results')\n",
    "\n",
    "Data_path=main_path+'/Data/'\n",
    "Data_results_path=main_path+'/Data_results/'\n",
    "json_file_path=Data_path+'results.json'\n",
    "json_file_path_small=Data_path+'results_small.json'\n",
    "validated_tsv_path=Data_path+'validated.tsv'\n",
    "validated_tsv_path_small=Data_path+'validated_small.tsv'\n",
    " \n",
    "\n",
    "validated_en_tsv_path=main_path+'/DeepSpeech/data/validated.tsv'\n",
    "validated_en_tsv_path_small=main_path+'/DeepSpeech/data/validated_small.tsv'\n",
    "\n",
    " \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "              audio_filepath   \n",
      "0  common_voice_de_31449916  \\\n",
      "1  common_voice_de_19730674   \n",
      "2  common_voice_de_19703888   \n",
      "3  common_voice_de_18507972   \n",
      "4  common_voice_de_24131267   \n",
      "5  common_voice_de_21905399   \n",
      "6  common_voice_de_20143462   \n",
      "7  common_voice_de_21889444   \n",
      "8  common_voice_de_18192538   \n",
      "9  common_voice_de_19615389   \n",
      "\n",
      "                                          transcript duration  \n",
      "0  er ist nach eustache de saint pierre der bekan...      4.9  \n",
      "1  eine erste kleinformatige vorstudie in bleisti...     10.1  \n",
      "2  er blieb ohne erfolg und lag in st\\u00e4ndigem...      9.0  \n",
      "3      mein garten ist teil eines kleingartenvereins      3.7  \n",
      "4  was habe ich damals f\\u00fcr einen unsinn getr...      3.6  \n",
      "5  der erste punkt bezieht sich auf die angst vor...      5.2  \n",
      "6  anschlie\\u00dfend war er bei der regierung in ...      4.1  \n",
      "7  jede quersubventionierung soll in zukunft unzu...     10.4  \n",
      "8  silke und marco verkr\\u00fcmelten sich unauff\\...      4.7  \n",
      "9  im frieden wurde die volksmarine aus dem komma...      9.0  \n",
      "49230\n"
     ]
    }
   ],
   "source": [
    "#@title read in all three CSV files at once and store them in separate dataframes\n",
    "\n",
    "\n",
    "# # my_data/all_overlap.txt ==>> test_at.txt\n",
    "# # transcript ==>> text\n",
    "# # file==>> audio_filepath\n",
    "# # all_overlap ==>> dataset_trans_test_all_duration_test_all_output.csv\n",
    "# ###############################################\n",
    "\n",
    "# df_at, df_gb, df_it, df_de_al, df_fr, df_de_ni, df_ch, df_de, df_us, df_ca, df_ru = pd.read_csv(['test_at.txt', 'test_gb.txt', 'test_it.txt', 'test_de_al.txt', 'test_fr.txt',\n",
    "#                                'test_de_ni.txt', 'test_ch.txt', 'test_de.txt', 'test_us.txt', 'test_ca.txt', 'test_ru.txt'] )\n",
    "\n",
    "MCV_all=pd.DataFrame({})\n",
    "\n",
    "\n",
    "df_at= pd.read_csv(Data_path+'test_at.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_gb= pd.read_csv(Data_path+'test_gb.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_it= pd.read_csv( Data_path+'test_it.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_de_al= pd.read_csv(Data_path+'test_de_al.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_fr= pd.read_csv(Data_path+'test_fr.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_de_ni= pd.read_csv( Data_path+'test_de_ni.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_ch= pd.read_csv(Data_path+'test_ch.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_de= pd.read_csv(Data_path+'test_de.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_us= pd.read_csv( Data_path+'test_us.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_ca= pd.read_csv(Data_path+'test_ca.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    "df_ru= pd.read_csv(Data_path+'test_ru.txt',delimiter = \", \", header = None ,encoding=\"utf-8\", names=['audio_filepath','transcript','duration'],engine='python' )\n",
    " \n",
    "# combine the dataframes into a single one \n",
    "combined_df = pd.concat([df_at, df_gb, df_it, df_de_al, df_fr, df_de_ni, df_ch, df_de, df_us, df_ca, df_ru], ignore_index=True)\n",
    "\n",
    "dataset_trans_test_all_duration=combined_df\n",
    "\n",
    "dataset_trans_test_all_duration['audio_filepath'] = dataset_trans_test_all_duration['audio_filepath'].map(lambda x: x.split('.',6)[2])\n",
    "dataset_trans_test_all_duration['audio_filepath'] = dataset_trans_test_all_duration['audio_filepath'].map(lambda x: x.split('/',6)[3])\n",
    "dataset_trans_test_all_duration['transcript'] = dataset_trans_test_all_duration['transcript'].map(lambda x: x.split('\": \"',2)[1])\n",
    "dataset_trans_test_all_duration['transcript'] = dataset_trans_test_all_duration['transcript'].map(lambda x: x.split('\"',2)[0])\n",
    "dataset_trans_test_all_duration['duration'] = dataset_trans_test_all_duration['duration'].map(lambda x: x.split('\": ',2)[1])\n",
    "dataset_trans_test_all_duration['duration'] = dataset_trans_test_all_duration['duration'].map(lambda x: x.split('}',2)[0])\n",
    "    \n",
    "\n",
    "print(type(dataset_trans_test_all_duration),'\\n',dataset_trans_test_all_duration.head(10))\n",
    "\n",
    "print(len(dataset_trans_test_all_duration))\n",
    "# the complete final dataframe of all Accents txt files\n",
    "dataset_trans_test_all_duration.to_csv( Data_results_path+'dataset_trans_test_all_duration.csv')\n",
    "\n",
    "MCV_all['audio_filepath']=dataset_trans_test_all_duration['audio_filepath']\n",
    "MCV_all['transcript']=dataset_trans_test_all_duration['transcript']\n",
    "\n",
    "MCV_all.to_csv( Data_results_path+'MCV_all.csv')\n",
    "\n",
    "\n",
    "dataset_trans_test_all_duration['transcript']\n",
    "\n",
    "transcripts = list(set(dataset_trans_test_all_duration['transcript'].tolist()))\n",
    "len(transcripts)\n",
    "trans_dict = {x:[] for x in transcripts}\n",
    "\n",
    "# Assign the row['transcript'] value to the \n",
    "for index, row in dataset_trans_test_all_duration.iterrows():\n",
    "    trans_dict[row['transcript']].append(row['audio_filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['common_voice_de_18946081', 'common_voice_de_18568843']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_dict['schreib ihr halt ein paar liebe worte rein']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
